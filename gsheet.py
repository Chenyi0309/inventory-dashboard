# -*- coding: utf-8 -*-
"""Google Sheets backend helpers.
Fill SHEET_URL and place your service_account.json in the project root.
The target worksheet MUST be named 'è´­å…¥/å‰©ä½™' (you can change the name below if needed).
"""
from __future__ import annotations

import os
from typing import Dict
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import streamlit as st  # ç”¨äºç¼“å­˜ï¼Œé™ä½ API è¯»é¢‘ç‡ï¼ˆé¿å…429ï¼‰

# ======== CONFIG ========
SHEET_URL = os.getenv("INVENTORY_SHEET_URL", "").strip()  # paste Sheet URL or set env var
WORKSHEET_NAME = os.getenv("INVENTORY_WORKSHEET_NAME", "è´­å…¥/å‰©ä½™")
INVENTORY_DEBUG = os.getenv("INVENTORY_DEBUG", "0").strip() in {"1", "true", "True"}

HEADERS = [
    "æ—¥æœŸ (Date)",
    "é£Ÿæåç§° (Item Name)",
    "åˆ†ç±» (Category)",
    "æ•°é‡ (Qty)",
    "å•ä½ (Unit)",
    "å•ä»· (Unit Price)",
    "æ€»ä»· (Total Cost)",
    "çŠ¶æ€ (Status)",    # ä¹°å…¥ / å‰©ä½™
    "å¤‡æ³¨ (Notes)"
]

STATUS_VALUES = ["ä¹°å…¥", "å‰©ä½™"]

# ================== åŸºç¡€ ==================

def _get_client():
    # Requires service_account.json in working dir
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_file("service_account.json", scopes=scopes)
    return gspread.authorize(creds)

def _get_ws():
    assert SHEET_URL, "Please set INVENTORY_SHEET_URL env var or hardcode SHEET_URL."
    gc = _get_client()
    sh = gc.open_by_url(SHEET_URL)
    try:
        ws = sh.worksheet(WORKSHEET_NAME)
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title=WORKSHEET_NAME, rows=1000, cols=len(HEADERS))
        ws.append_row(HEADERS)
    return ws

def ensure_headers(ws=None):
    ws = ws or _get_ws()
    values = ws.get_values("1:1")
    if not values or not values[0]:
        ws.update("1:1", [HEADERS])
    else:
        # if header mismatch, do nothing (avoid overwriting user sheet);
        pass

# ================== å†™å…¥ ==================

def append_record(record: Dict):
    ws = _get_ws()
    ensure_headers(ws)

    row = [
        record.get("æ—¥æœŸ (Date)",""),
        record.get("é£Ÿæåç§° (Item Name)","").strip(),
        record.get("åˆ†ç±» (Category)","").strip(),
        record.get("æ•°é‡ (Qty)",""),
        record.get("å•ä½ (Unit)","").strip(),
        record.get("å•ä»· (Unit Price)",""),
        record.get("æ€»ä»· (Total Cost)",""),
        record.get("çŠ¶æ€ (Status)",""),
        record.get("å¤‡æ³¨ (Notes)","").strip(),
    ]
    ws.append_row(row, value_input_option="USER_ENTERED")

# ================== è¯» & æ¸…æ´— & è°ƒè¯• ==================

def _normalize_aliases(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ—ååˆ«åå¯¹é½"""
    aliases = {
        "æ—¥æœŸ": "æ—¥æœŸ (Date)",
        "é£Ÿæåç§°": "é£Ÿæåç§° (Item Name)",
        "ç‰©å“å": "é£Ÿæåç§° (Item Name)",
        "ç‰©å“åç§°": "é£Ÿæåç§° (Item Name)",
        "ç±»åˆ«": "åˆ†ç±» (Category)",
        "åˆ†ç±»": "åˆ†ç±» (Category)",
        "æ•°é‡": "æ•°é‡ (Qty)",
        "å•ä½": "å•ä½ (Unit)",
        "å•ä»·": "å•ä»· (Unit Price)",
        "æ€»ä»·": "æ€»ä»· (Total Cost)",
        "çŠ¶æ€": "çŠ¶æ€ (Status)",
        "å¤‡æ³¨": "å¤‡æ³¨ (Notes)",
    }
    for old, new in aliases.items():
        if old in df.columns and new not in df.columns:
            df[new] = df.pop(old)
    # ç¡®ä¿æ‰€æœ‰åˆ—å­˜åœ¨
    for col in HEADERS:
        if col not in df.columns:
            df[col] = None
    return df

def _normalize_values(df: pd.DataFrame) -> pd.DataFrame:
    """å­—ç¬¦ä¸²å»ç©ºæ ¼/æ¸… Noneï¼ŒçŠ¶æ€å½’ä¸€ï¼Œæ•°å€¼åˆ—è½¬æ•°å€¼ï¼Œè‡ªåŠ¨è¡¥æ€»ä»·"""
    # æ¸…å­—ç¬¦ä¸²åˆ—
    for c in ["é£Ÿæåç§° (Item Name)", "åˆ†ç±» (Category)", "å•ä½ (Unit)", "çŠ¶æ€ (Status)", "å¤‡æ³¨ (Notes)"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()
            df[c] = df[c].replace({"None": "", "nan": ""})

    # çŠ¶æ€å½’ä¸€
    if "çŠ¶æ€ (Status)" in df.columns:
        df["çŠ¶æ€ (Status)"] = df["çŠ¶æ€ (Status)"].replace({
            "è´­ä¹°": "ä¹°å…¥", "é‡‡è´­": "ä¹°å…¥", "è¿›è´§": "ä¹°å…¥",
            "åº“å­˜": "å‰©ä½™", "ä½™é‡": "å‰©ä½™", "ä½™": "å‰©ä½™"
        })

    # æ—¥æœŸè§£æ
    def _parse_date(x):
        if pd.isna(x) or x == "":
            return pd.NaT
        try:
            return pd.to_datetime(x)
        except Exception:
            try:
                # Excel serial date
                return pd.to_datetime("1899-12-30") + pd.to_timedelta(float(x), unit="D")
            except Exception:
                return pd.NaT
    df["æ—¥æœŸ (Date)"] = df["æ—¥æœŸ (Date)"].apply(_parse_date)

    # æ•°å€¼åˆ—
    for c in ["æ•°é‡ (Qty)", "å•ä»· (Unit Price)", "æ€»ä»· (Total Cost)"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # è‡ªåŠ¨è¡¥æ€»ä»·ï¼ˆä¹°å…¥è¡Œï¼‰
    mask_buy = df["çŠ¶æ€ (Status)"].eq("ä¹°å…¥")
    need_total = mask_buy & df["æ€»ä»· (Total Cost)"].isna()
    df.loc[need_total, "æ€»ä»· (Total Cost)"] = df.loc[need_total, "æ•°é‡ (Qty)"] * df.loc[need_total, "å•ä»· (Unit Price)"]

    # ä¸¢å¼ƒâ€œé£Ÿæåç§°â€ä¸ºç©ºçš„è¡Œ
    df = df[df["é£Ÿæåç§° (Item Name)"].astype(str).str.strip() != ""].copy()

    return df

def _debug_write(title: str, obj):
    """åœ¨ Streamlit/æ—¥å¿—é‡Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯"""
    try:
        st.write(title, obj)
    except Exception:
        print(f"[DEBUG] {title}")
        try:
            print(obj)
        except Exception:
            pass

def read_records() -> pd.DataFrame:
    ws = _get_ws()
    ensure_headers(ws)
    records = ws.get_all_records()
    raw_df = pd.DataFrame(records)

    # è°ƒè¯•ï¼šåŸå§‹å‰20è¡Œ
    _debug_write("âœ… åŸå§‹æ•°æ®ï¼ˆå‰20è¡Œï¼‰", raw_df.head(20))

    # åˆ«å & è¡¥åˆ—
    df = _normalize_aliases(raw_df)

    # æ¸…æ´—å½’ä¸€
    df = _normalize_values(df)

    # è°ƒè¯•ï¼šæ¸…æ´—åä¿¡æ¯
    _debug_write("âœ… æ¸…æ´—åå½¢çŠ¶", df.shape)
    _debug_write("âœ… æ¸…æ´—ååˆ—å", list(df.columns))
    _debug_write("âœ… æ¸…æ´—åæ ·ä¾‹ï¼ˆå‰10è¡Œï¼‰", df.head(10))
    if "çŠ¶æ€ (Status)" in df.columns:
        _debug_write("âœ… çŠ¶æ€åˆ†å¸ƒ", df["çŠ¶æ€ (Status)"].value_counts(dropna=False))
    if "åˆ†ç±» (Category)" in df.columns:
        _debug_write("âœ… åˆ†ç±»åˆ†å¸ƒ", df["åˆ†ç±» (Category)"].value_counts(dropna=False))

    if INVENTORY_DEBUG:
        # é¢å¤–è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        try:
            buf = []
            buf.append("DataFrame info:")
            buf.append(str(df.dtypes))
            _debug_write("ğŸ§ª é¢å¤–è¯Šæ–­", "\n".join(buf))
        except Exception:
            pass

    return df

# ================== ä¸»æ•°æ®ï¼ˆç‰©å“æ¸…å•ï¼‰ ==================

def read_catalog():
    """è¯»å–ç‰©å“ä¸»æ•°æ®è¡¨ï¼Œä¼˜å…ˆ ['åº“å­˜äº§å“','Content_tracker','ç‰©å“æ¸…å•']"""
    ws_names_try = ["åº“å­˜äº§å“", "Content_tracker", "ç‰©å“æ¸…å•"]
    ws = _get_ws()   # åªä¸ºæ‹¿åˆ° spreadsheet å¯¹è±¡
    sh = ws.spreadsheet

    target = None
    for name in ws_names_try:
        try:
            target = sh.worksheet(name)
            break
        except Exception:
            continue
    if target is None:
        return pd.DataFrame(columns=["ç‰©å“å","ç±»å‹","å•ä½","å¤‡æ³¨"])

    df = pd.DataFrame(target.get_all_records())

    # åˆ—åæ˜ å°„
    aliases = {
        "ç‰©å“å": "ç‰©å“å",
        "ç‰©å“åç§°": "ç‰©å“å",
        "ç‰©å“": "ç‰©å“å",
        "ç‰©å“åç§° (Item)": "ç‰©å“å",

        "ç±»å‹": "ç±»å‹",
        "ç±»åˆ«": "ç±»å‹",
        "åˆ†ç±»": "ç±»å‹",

        "å•ä½": "å•ä½",
        "å¤‡æ³¨": "å¤‡æ³¨"
    }
    for old, new in aliases.items():
        if old in df.columns and new not in df.columns:
            df[new] = df.pop(old)

    # åªä¿ç•™å…³é”®åˆ—
    keep = [c for c in ["ç‰©å“å","ç±»å‹","å•ä½","å¤‡æ³¨"] if c in df.columns]
    df = df[keep].copy()

    # æ¸…æ´—
    for c in df.columns:
        if c in ["ç‰©å“å","ç±»å‹","å•ä½","å¤‡æ³¨"]:
            df[c] = df[c].astype(str).str.strip()

    # è¿‡æ»¤ç©ºç‰©å“å
    df = df[df["ç‰©å“å"].astype(bool)]
    return df

# ================== ç¼“å­˜ & æ¸…ç¼“å­˜ ==================

@st.cache_data(show_spinner=False, ttl=60)
def read_records_cached() -> pd.DataFrame:
    """ç¼“å­˜è¯»å–â€˜è´­å…¥/å‰©ä½™â€™ 60 ç§’ã€‚"""
    return read_records()

@st.cache_data(show_spinner=False, ttl=60)
def read_catalog_cached() -> pd.DataFrame:
    """ç¼“å­˜è¯»å–ä¸»æ•°æ®ï¼ˆåº“å­˜äº§å“/Content_tracker/ç‰©å“æ¸…å•ï¼‰60 ç§’ã€‚"""
    return read_catalog()

def bust_cache():
    """æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜ï¼ˆåœ¨é¡µé¢ä¸Šåšâ€œåˆ·æ–°æ•°æ®â€æŒ‰é’®æ—¶è°ƒç”¨ï¼‰"""
    try:
        st.cache_data.clear()
    except Exception:
        pass
