# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

# ================= Secrets/ENV =================
# å°† service account å†™å…¥æœ¬åœ°ï¼Œä¾› gspread ä½¿ç”¨
if "service_account" in st.secrets:
    with open("service_account.json", "w") as f:
        json.dump(dict(st.secrets["service_account"]), f)

# è¯»å– Sheet URLï¼ˆsecrets ä¼˜å…ˆç”Ÿæ•ˆï¼‰
sheet_url = st.secrets.get("INVENTORY_SHEET_URL", None) or os.getenv("INVENTORY_SHEET_URL", None)
if sheet_url:
    os.environ["INVENTORY_SHEET_URL"] = sheet_url

# ================ Backend ======================
# è¯»å†™ Google Sheet
from gsheet import append_records_bulk
try:
    from gsheet import (
        read_records_cached as read_records_fn,
        read_catalog_cached as read_catalog_fn,
        bust_cache,
    )
except Exception:
    from gsheet import read_records as read_records_fn, read_catalog as read_catalog_fn
    def bust_cache(): pass

# ç»Ÿè®¡è®¡ç®—/åˆ—åè§„èŒƒåŒ–
try:
    from compute import compute_stats, _recent_usage_14d_robust as _recent_usage_14d_new, normalize_columns as normalize_columns_compute
except Exception:
    from compute import compute_stats, _recent_usage_14d_new
    def normalize_columns_compute(df: pd.DataFrame) -> pd.DataFrame:
        return df

# å…è®¸çš„å››ä¸ªç±»åˆ«ï¼ˆç¡¬ç¼–ç ï¼‰
ALLOWED_CATS = ["é£Ÿç‰©ç±»", "æ¸…æ´ç±»", "æ¶ˆè€—å“", "é¥®å“ç±»"]
DEFAULT_CAT = "é£Ÿç‰©ç±»"

# ============== ä»…ç”¨äºå½•å…¥é¡µçš„è½»é‡å·¥å…· ==============
def safe_sort(df: pd.DataFrame, by: str, ascending=True):
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def normalize_cat(x: str) -> str:
    if x is None:
        return DEFAULT_CAT
    s = str(x).strip()
    if s == "" or s.lower() in ("nan", "none"):
        return DEFAULT_CAT
    return s if s in ALLOWED_CATS else DEFAULT_CAT

def _blank_if_none(x):
    try:
        if x is None or (isinstance(x, float) and pd.isna(x)):
            return ""
    except Exception:
        pass
    return x

def build_item_order_from_catalog() -> dict:
    """
    ä»ã€åº“å­˜äº§å“ã€sheet çš„è¡Œé¡ºåºæ„å»ºç‰©å“æ˜¾ç¤ºé¡ºåºã€‚
    è¿”å›å½¢å¦‚ {ç‰©å“å: é¡ºåºå·} çš„æ˜ å°„ï¼›é¡ºåºå·è¶Šå°è¶Šé å‰ã€‚
    å¦‚æœè¯»ä¸åˆ°ä¸»æ¸…å•ï¼Œåˆ™è¿”å›ç©º dictï¼ˆåé¢ä¼šèµ°å…œåº•ï¼‰ã€‚
    """
    try:
        cat = read_catalog_fn()  # å¤ç”¨ä½ å·²æœ‰çš„è¯»å–ä¸»æ•°æ®å‡½æ•°
    except Exception:
        cat = pd.DataFrame()

    if cat is None or cat.empty or "ç‰©å“å" not in cat.columns:
        return {}

    order = {}
    seen = set()
    # æŒ‰åœ¨ä¸»æ¸…å•ä¸­çš„å‡ºç°é¡ºåºè®°å½•ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®
    for idx, x in enumerate(list(cat["ç‰©å“å"].astype(str))):
        name = x.strip()
        if name and name not in seen:
            order[name] = idx
            seen.add(name)
    return order

# ---------- æŠŠæ•°é‡è§£ææˆè¡¨æ ¼è¦å†™çš„å½¢æ€ ----------
def to_qty_cell(raw, unit_in: str):
    """
    è¿”å›: (qty_cell, unit_out, is_pct)
    - è‹¥æ•°é‡é‡Œå¸¦ '%' æˆ– å•ä½æ˜¯ç™¾åˆ†å· -> is_pct=Trueï¼Œqty_cell æ˜¯ '50%' è¿™æ ·çš„å­—ç¬¦ä¸²ï¼›
    - å…¶ä»–æƒ…å†µ -> is_pct=Falseï¼Œqty_cell æ˜¯æ•°å­—(float æˆ– NaN)ï¼›
    - unit_out: å½“å•ä½ä¸æ˜¯ % æ—¶æŒ‰ç”¨æˆ·å¡«å†™è¿”å›ï¼›è‹¥å•ä½å†™æˆ %/percent/ç™¾åˆ†æ¯”/ratioï¼Œåˆ™è¿”å›ç©ºä¸²ã€‚
    """
    s = "" if raw is None else str(raw).strip()
    unit_norm = (unit_in or "").replace("ï¼…", "%").strip()

    # æ•°é‡é‡Œå¸¦ç™¾åˆ†å·
    if s.endswith("%"):
        num = pd.to_numeric(s[:-1], errors="coerce")
        if pd.isna(num):
            return "", ("" if unit_norm == "%" else unit_norm), True
        # å†™å›å»å°±æ˜¯ '50%' è¿™ç§ï¼›å°½é‡å»æ‰å¤šä½™å°æ•°
        numf = float(num)
        qty_txt = f"{int(numf)}%" if numf.is_integer() else f"{numf}%"
        return qty_txt, ("" if unit_norm == "%" else unit_norm), True

    # å•ä½æ˜¯ç™¾åˆ†å·
    if unit_norm in {"%", "percent", "ç™¾åˆ†æ¯”", "ratio"}:
        num = pd.to_numeric(s, errors="coerce")
        if pd.isna(num):
            return "", "", True
        numf = float(num)
        qty_txt = f"{int(numf)}%" if numf.is_integer() else f"{numf}%"
        return qty_txt, "", True

    # æ™®é€šæ•°é‡
    return pd.to_numeric(s, errors="coerce"), unit_norm, False

def _pct_ratio(qty_cell):
    """'50%' -> 0.5ï¼›å¦åˆ™è¿”å› NaNã€‚ä»…ç”¨äºé‡‘é¢è®¡ç®—ç­‰æ•°å€¼åœºæ™¯ã€‚"""
    if isinstance(qty_cell, str) and qty_cell.strip().endswith("%"):
        try:
            return float(qty_cell.strip()[:-1]) / 100.0
        except Exception:
            return np.nan
    return np.nan

# ---------- å±•ç¤ºï¼šè¡¨æ ¼å±…ä¸­ ----------
# ---------- å±•ç¤ºï¼šè¡¨æ ¼å±…ä¸­ + ä¸¤ä½å°æ•° ----------
def render_centered_table(df: pd.DataFrame):
    # æ‰¾å‡ºæ‰€æœ‰æ•°å€¼åˆ—
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # ä¸ºæ•°å€¼åˆ—ç»Ÿä¸€è®¾ç½®ä¸¤ä½å°æ•°
    fmt_map = {c: "{:.2f}" for c in num_cols}

    styler = (
        df.style
          .format(fmt_map)  # ä¸¤ä½å°æ•°
          .set_properties(**{"text-align": "center"})  # å•å…ƒæ ¼å±…ä¸­
          .set_table_styles([
              {"selector": "th", "props": [("text-align", "center")]},        # è¡¨å¤´å±…ä¸­
              {"selector": "th.col_heading", "props": [("text-align", "center")]},
              {"selector": "th.row_heading", "props": [("text-align", "center")]},
          ])
    )

    # ä¼˜å…ˆç”¨äº¤äº’è¡¨ï¼›å¦‚æœç‰ˆæœ¬ä¸æ”¯æŒæ ·å¼ï¼Œå°±é™çº§ä¸ºé™æ€è¡¨
    try:
        st.dataframe(styler, use_container_width=True)
    except Exception:
        st.table(styler)


# ================ APP UI =======================
st.set_page_config(page_title="Gangnam åº“å­˜ç®¡ç†", layout="wide")

# é¡¶éƒ¨å¸ƒå±€ï¼šå·¦è¾¹ logoï¼Œå³è¾¹æ ‡é¢˜è¯´æ˜
c1, c2 = st.columns([1, 6])
with c1:
    st.image("gangnam_logo.png", width=180)

with c2:
    st.markdown(
        """
        <div style="display:flex; flex-direction:column; justify-content:center; height:100%;">
            <h1 style="margin-bottom:0;">Gangnam åº“å­˜ç®¡ç†</h1>
            <p style="color:gray; font-size:16px; margin-top:4px;">
                å½•å…¥â€˜ä¹°å…¥/å‰©ä½™â€™ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°è¡¨æ ¼ï¼Œå¹¶å®æ—¶ç”Ÿæˆâ€˜åº“å­˜ç»Ÿè®¡â€™åˆ†æ
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )

tabs = st.tabs(["â• å½•å…¥è®°å½•", "ğŸ“Š åº“å­˜ç»Ÿè®¡"])

# ================== å½•å…¥è®°å½• ==================
with tabs[0]:
    st.subheader("å½•å…¥æ–°è®°å½•")

    # è¯»å–â€œè´­å…¥/å‰©ä½™â€ç”¨äºæ¨æ–­å·²æœ‰ç‰©å“ï¼ˆå½“æ²¡æœ‰ä¸»æ•°æ®æ—¶ï¼‰
    try:
        df_all = read_records_fn()
        df_all = normalize_columns_compute(df_all)  # ä½¿ç”¨ compute çš„å¼ºåŠ›æ¸…æ´—
    except Exception:
        df_all = pd.DataFrame()

    # ä¸»æ•°æ®ï¼ˆåº“å­˜äº§å“ï¼‰
    try:
        catalog = read_catalog_fn()
    except Exception:
        catalog = pd.DataFrame()

    c1, c2, c3 = st.columns(3)
    sel_date   = c1.date_input("æ—¥æœŸ (Date)", pd.Timestamp.today())
    sel_type   = c2.selectbox("ç±»å‹ï¼ˆå¤§ç±»ï¼‰", ALLOWED_CATS, index=0)
    sel_status = c3.selectbox("çŠ¶æ€ (Status)", ["ä¹°å…¥", "å‰©ä½™"])

    # æ„é€ å¯ç¼–è¾‘è¡¨ï¼šä¼˜å…ˆä¸»æ•°æ®ï¼Œå¦åˆ™å†å²è®°å½•ä¸­è¯¥ç±»çš„æœ€è¿‘å•ä½
    if not catalog.empty and {"ç‰©å“å", "å•ä½", "ç±»å‹"}.issubset(catalog.columns):
        catalog = catalog.copy()
        catalog["ç±»å‹"] = catalog["ç±»å‹"].apply(normalize_cat)
        base = (catalog[catalog["ç±»å‹"] == sel_type][["ç‰©å“å", "å•ä½"]]
                .drop_duplicates()
                .reset_index(drop=True))
    else:
        if not df_all.empty:
            tmp = df_all.copy()
            if "åˆ†ç±» (Category)" not in tmp.columns:
                tmp["åˆ†ç±» (Category)"] = DEFAULT_CAT
            tmp["åˆ†ç±» (Category)"] = tmp["åˆ†ç±» (Category)"].apply(normalize_cat)
            latest_unit = (
                safe_sort(tmp[tmp["åˆ†ç±» (Category)"] == sel_type], "æ—¥æœŸ (Date)")
                .groupby("é£Ÿæåç§° (Item Name)")["å•ä½ (Unit)"]
                .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else "")
                .reset_index()
                .rename(columns={"é£Ÿæåç§° (Item Name)": "ç‰©å“å", "å•ä½ (Unit)": "å•ä½"})
            )
            base = latest_unit
        else:
            base = pd.DataFrame(columns=["ç‰©å“å", "å•ä½"])

    # ---------- æ„é€ å¯ç¼–è¾‘è¡¨ ----------
    edit_df = base.copy()
    for col in ["ç‰©å“å", "å•ä½"]:
        if col not in edit_df.columns:
            edit_df[col] = ""
    # æ•°é‡ç”¨å­—ç¬¦ä¸²å ä½ï¼Œä¾¿äº TextColumn æ¥å— '20%' è¿™ç±»è¾“å…¥
    edit_df["æ•°é‡"] = ""
    if sel_status == "ä¹°å…¥":
        edit_df["å•ä»·"] = np.nan
    edit_df["å¤‡æ³¨"] = ""

    st.markdown("**åœ¨ä¸‹è¡¨ä¸­å¡«å†™æ•°é‡ï¼ˆå¿…å¡«ï¼‰ï¼Œå•ä»·ä»…åœ¨ä¹°å…¥æ—¶å¡«å†™ï¼›å¯æ·»åŠ æ–°è¡Œå½•å…¥æ–°ç‰©å“**")

    edited = st.data_editor(
        edit_df.astype({"æ•°é‡": "object"}),  # æ˜ç¡®æŠŠâ€œæ•°é‡â€è®¾ä¸º object/str
        use_container_width=True,
        num_rows="dynamic",
        column_config={
            "æ•°é‡": st.column_config.TextColumn(help="æ”¯æŒ 3ã€0.5 æˆ– 20%"),
            "å•ä»·": st.column_config.NumberColumn(step=0.01, min_value=0.0) if sel_status == "ä¹°å…¥" else None,
        },
        key="bulk_editor",
    )

    # æ‰¹é‡å†™å…¥ Google Sheet
    if st.button("âœ… æ‰¹é‡ä¿å­˜åˆ°ã€è´­å…¥/å‰©ä½™ã€"):
        dt = pd.to_datetime(sel_date)
        payload = []
        preview = []

        for _, r in edited.iterrows():
            name = str(r.get("ç‰©å“å", "") or "").strip()
            if not name:
                continue

            unit_in = str(r.get("å•ä½", "") or "").strip()
            qty_cell, unit_out, is_pct = to_qty_cell(r.get("æ•°é‡", ""), unit_in)

            # ---- ä¹°å…¥ / å‰©ä½™ çš„æ ¡éªŒä¸è½è¡¨å€¼ ----
            if sel_status == "ä¹°å…¥":
                # å…è®¸ç™¾åˆ†æ¯”æˆ–çº¯æ•°å­—ï¼›éƒ½å¿…é¡» > 0
                if is_pct:
                    ratio = _pct_ratio(qty_cell)   # '50%' -> 0.5
                    if not (pd.notna(ratio) and ratio > 0):
                        continue
                    qty_to_sheet = qty_cell       # å†™ '50%' åˆ°â€œæ•°é‡â€
                    qty_for_cost = ratio          # é‡‘é¢ç”¨ 0.5 å‚ä¸è®¡ç®—
                else:
                    try:
                        qty_num = float(qty_cell)
                    except Exception:
                        qty_num = np.nan
                    if not (pd.notna(qty_num) and qty_num > 0):
                        continue
                    qty_to_sheet = qty_num        # å†™æ•°å­—åˆ°â€œæ•°é‡â€
                    qty_for_cost = qty_num        # é‡‘é¢ç”¨æ•°å­—
            else:
                # å‰©ä½™ï¼šå…è®¸ç™¾åˆ†æ¯”æˆ–æ•°å­—ï¼ˆå¯=0ï¼‰
                if is_pct:
                    qty_to_sheet = qty_cell       # '50%' åŸæ ·å†™å›
                else:
                    try:
                        qty_num = float(qty_cell)
                    except Exception:
                        qty_num = np.nan
                    if pd.isna(qty_num):          # å‰©ä½™è‡³å°‘è¦èƒ½è§£ææˆæ•°å­—(å¯=0)æˆ–æ˜¯ç™¾åˆ†æ¯”
                        continue
                    qty_to_sheet = qty_num
                qty_for_cost = None               # å‰©ä½™ä¸è®¡æ€»ä»·

            # ---- ä»·æ ¼ / æ€»ä»· ----
            price = None
            total = None
            if sel_status == "ä¹°å…¥" and pd.notna(r.get("å•ä»·", np.nan)):
                try:
                    price = float(r["å•ä»·"])
                except Exception:
                    price = None
                if price is not None:
                    # è‹¥æ˜¯ç™¾åˆ†æ¯”ä¹°å…¥ï¼Œç”¨ ratio è®¡ç®—é‡‘é¢ï¼›å¦åˆ™ç”¨æ•°å­—æ•°é‡
                    factor = qty_for_cost if qty_for_cost is not None else np.nan
                    if pd.notna(factor):
                        total = round(float(factor) * price, 2)

            # ---- ç»„è£…å†™å…¥è¡Œ ----
            record = {
                "æ—¥æœŸ (Date)": f"=DATE({dt.year},{dt.month},{dt.day})",
                "é£Ÿæåç§° (Item Name)": name,
                "åˆ†ç±» (Category)": sel_type,
                "æ•°é‡ (Qty)": qty_to_sheet,            # å¯èƒ½æ˜¯æ•°å­—ï¼Œä¹Ÿå¯èƒ½æ˜¯ '50%'
                "å•ä½ (Unit)": unit_out,               # æ­£å¸¸å•ä½ï¼›è‹¥ç”¨æˆ·å¡«äº† % åˆ™ç½®ç©º
                "å•ä»· (Unit Price)": "" if price is None else price,
                "æ€»ä»· (Total Cost)": "" if total is None else total,
                "çŠ¶æ€ (Status)": sel_status,
                "å¤‡æ³¨ (Notes)": str(r.get("å¤‡æ³¨", "") or "").strip(),
            }
            payload.append(record)

            # ---- é¢„è§ˆ ----
            row_preview = {
                "æ—¥æœŸ": dt.date().isoformat(),
                "ç‰©å“å": name,
                "æ•°é‡": qty_to_sheet,
                "å•ä½": unit_out,
                "çŠ¶æ€": sel_status,
            }
            if sel_status == "ä¹°å…¥":
                row_preview["å•ä»·"] = "" if price is None else price
                row_preview["æ€»ä»·"] = "" if total is None else total
            preview.append(row_preview)

        # 3) æ‰¹é‡å†™å…¥ + æ˜¾ç¤ºå†™å…¥æ˜ç»† + å›è¯»æ ¡éªŒ
        try:
            if payload:
                resp = append_records_bulk(payload)  # gsheet å†…éƒ¨å·²ç”¨ USER_ENTERED + table_range="A1"
                st.success(f"å·²æˆåŠŸå†™å…¥ {len(payload)} æ¡è®°å½•ï¼")
                st.caption(f"ç›®æ ‡è¡¨ï¼š{st.secrets.get('INVENTORY_SHEET_URL') or os.getenv('INVENTORY_SHEET_URL')}")

                # æ˜¾ç¤º Google è¿”å›çš„å†™å…¥åŒºé—´ï¼ˆç”¨äºå®šä½ï¼‰
                from gsheet import parse_updated_range_rows, tail_rows
                rng = resp.get("updates", {}).get("updatedRange", "")
                st.caption(f"Google è¿”å›å†™å…¥åŒºé—´ï¼š{rng}")
                rows_info = parse_updated_range_rows(resp)
                if rows_info:
                    st.caption(f"ï¼ˆèµ·æ­¢è¡Œå·ï¼š{rows_info[0]}â€“{rows_info[1]}ï¼‰")

                # è¡¨å°¾å¿«ç…§
                with st.expander("ğŸ” è¡¨å°¾å¿«ç…§ï¼ˆæœ€è¿‘ 10 è¡Œï¼‰", expanded=False):
                    st.dataframe(tail_rows(10), use_container_width=True)

                # æœ¬æ¬¡å†™å…¥çš„è®°å½•ï¼ˆé¢„è§ˆï¼‰
                pre_df = pd.DataFrame(preview)
                if sel_status == "ä¹°å…¥":
                    pre_df = pre_df[["æ—¥æœŸ", "ç‰©å“å", "æ•°é‡", "å•ä½", "å•ä»·", "æ€»ä»·", "çŠ¶æ€"]]
                    with pd.option_context("mode.use_inf_as_na", True):
                        total_spent = pd.to_numeric(pre_df.get("æ€»ä»·"), errors="coerce").sum()
                    st.caption(f"æœ¬æ¬¡ä¹°å…¥åˆè®¡é‡‘é¢ï¼š{total_spent:.2f}")
                else:
                    pre_df = pre_df[["æ—¥æœŸ", "ç‰©å“å", "æ•°é‡", "å•ä½", "çŠ¶æ€"]]
                st.markdown("**æœ¬æ¬¡å†™å…¥çš„è®°å½•**")
                st.dataframe(pre_df, use_container_width=True)

                # å›è¯»æ ¡éªŒ
                try:
                    bust_cache()
                except Exception:
                    pass
                try:
                    df_check = read_records_fn()
                    df_check = normalize_columns_compute(df_check)
                    dd = pd.to_datetime(df_check.get("æ—¥æœŸ (Date)"), errors="coerce").dt.date
                    names = [p["ç‰©å“å"] for p in preview]
                    just_now = df_check[
                        (dd == dt.date()) &
                        (df_check.get("çŠ¶æ€ (Status)") == sel_status) &
                        (df_check.get("é£Ÿæåç§° (Item Name)").isin(names))
                    ][["æ—¥æœŸ (Date)","é£Ÿæåç§° (Item Name)","æ•°é‡ (Qty)","çŠ¶æ€ (Status)"]].copy()
                    st.markdown("**å†™å…¥åçš„å›è¯»æ ¡éªŒ**")
                    if just_now.empty:
                        st.warning("è¡¨é‡Œæš‚æœªè¯»åˆ°åˆšå†™å…¥çš„è¡Œï¼ˆå¯èƒ½è¢«è¡¨æ ¼æ ¼å¼/åº•éƒ¨ç©ºç™½å½±å“ï¼‰ã€‚è‹¥ä»æœªå‡ºç°ï¼Œè¯·æ¸…ç†è¡¨åº•éƒ¨å¤šä½™æ ¼å¼ï¼Œå¹¶ç¡®è®¤ gsheet.append ä½¿ç”¨ USER_ENTERED + table_range='A1'ã€‚")
                    else:
                        st.dataframe(just_now.sort_values("æ—¥æœŸ (Date)"), use_container_width=True)
                except Exception:
                    pass

            else:
                st.info("æ²¡æœ‰å¯å†™å…¥çš„è®°å½•ã€‚")
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")

# ================== åº“å­˜ç»Ÿè®¡ ==================
with tabs[1]:
    st.subheader("åº“å­˜ç»Ÿè®¡")

    colR1, _ = st.columns([1, 3])
    if colR1.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è¯»å– Google Sheet"):
        try:
            bust_cache()
        except Exception:
            pass
        st.rerun()

    # è¯»æ˜ç»†å¹¶ç»Ÿä¸€åˆ—å â€”â€” ä½¿ç”¨ compute çš„è§„èŒƒåŒ–
    try:
        df = read_records_fn()
        df = normalize_columns_compute(df)
    except Exception as e:
        st.error(f"è¯»å–è¡¨æ ¼å¤±è´¥ï¼š{e}")
        st.stop()

    # è°ƒè¯•é¢æ¿ï¼šçœ‹çœ‹å®é™…è¯»åˆ°äº†ä»€ä¹ˆ
    with st.expander("ğŸ” è°ƒè¯•ï¼šæŸ¥çœ‹åŸå§‹æ•°æ®å¿«ç…§", expanded=False):
        st.write("shape:", df.shape)
        st.write("columns:", list(df.columns))
        for col in ["æ—¥æœŸ (Date)", "é£Ÿæåç§° (Item Name)", "åˆ†ç±» (Category)", "çŠ¶æ€ (Status)"]:
            if col in df.columns:
                st.write(f"{col} éç©ºæ•°é‡:", int(df[col].notna().sum()))
            else:
                st.write(f"âš ï¸ æœªè¯†åˆ«åˆ—ï¼š{col}")
        if not df.empty:
            st.dataframe(df.head(10), use_container_width=True)

    # å…œåº•åˆ†ç±»
    if "åˆ†ç±» (Category)" not in df.columns:
        df["åˆ†ç±» (Category)"] = DEFAULT_CAT
    else:
        df["åˆ†ç±» (Category)"] = df["åˆ†ç±» (Category)"].apply(normalize_cat)

    # ç»Ÿè®¡è¡¨
    stats_all = compute_stats(df)

    # é™„ä¸Šâ€œç±»å‹â€åˆ—ç”¨äºç­›é€‰ï¼ˆå–è¯¥ç‰©å“æœ€è¿‘ä¸€æ¬¡çš„åˆ†ç±»ï¼‰
    if not df.empty and "é£Ÿæåç§° (Item Name)" in df.columns:
        latest_cat = (
            df.sort_values("æ—¥æœŸ (Date)")
              .groupby("é£Ÿæåç§° (Item Name)")["åˆ†ç±» (Category)"]
              .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else DEFAULT_CAT)
        )
        stats_all = stats_all.merge(
            latest_cat.rename("ç±»å‹"),
            left_on="é£Ÿæåç§° (Item Name)", right_index=True, how="left"
        )
    else:
        stats_all["ç±»å‹"] = DEFAULT_CAT
    stats_all["ç±»å‹"] = stats_all["ç±»å‹"].apply(normalize_cat)

    # ---------- å›ºå®šæ˜¾ç¤ºé¡ºåºï¼šæ¥è‡ªã€åº“å­˜äº§å“ã€çš„è¡Œé¡ºåº ----------
    def _norm_name(s):
        # å»å‰åç©ºæ ¼ + å»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼Œé¿å…â€œçœ‹ä¸è§çš„ç©ºæ ¼â€å½±å“åŒ¹é…
        return (str(s) if s is not None else "").strip().replace(" ", "")

    try:
        order_df = read_catalog_fn().copy()
    except Exception:
        order_df = pd.DataFrame()

    if not order_df.empty and "ç‰©å“å" in order_df.columns:
        order_df["ç±»å‹"] = order_df.get("ç±»å‹", "").apply(normalize_cat)
        order_df["name_norm"] = order_df["ç‰©å“å"].map(_norm_name)
        order_df["__order__"] = np.arange(len(order_df), dtype=float)
        order_map = dict(zip(order_df["name_norm"], order_df["__order__"]))
    else:
        order_map = {}

    BIG = float(1e9)  # åŒ¹é…ä¸åˆ°çš„æ”¾åˆ°æœ€å
    stats_all["name_norm"] = stats_all["é£Ÿæåç§° (Item Name)"].map(_norm_name)
    stats_all["__order__"] = stats_all["name_norm"].map(order_map).fillna(BIG)

    # === ç­›é€‰æ¡ï¼ˆä½œç”¨äºä¸‹æ–¹ç»“æœè¡¨ï¼‰ ===
    st.markdown("#### ç­›é€‰")
    fc1, _ = st.columns([1, 3])
    sel_type_bar = fc1.selectbox("é€‰æ‹©åˆ†ç±»", ["å…¨éƒ¨"] + ALLOWED_CATS, index=0)

    stats = stats_all if sel_type_bar == "å…¨éƒ¨" else stats_all[stats_all["ç±»å‹"].eq(sel_type_bar)]
    stats = stats.copy()

    # é¢„è­¦è§„åˆ™ï¼šç™¾åˆ†æ¯”(<20%)ï¼›éç™¾åˆ†æ¯”(é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°<3)
    def _is_percent_row(row: pd.Series) -> bool:
        name = str(row.get("é£Ÿæåç§° (Item Name)", "") or "")
        unit = str(row.get("å•ä½ (Unit)", "") or "").strip()
        last_rem = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
    
        # 1) åç§°é‡Œå¸¦â€œç³–æµ†â€ç›´æ¥æŒ‰ç™¾åˆ†æ¯”å¤„ç†ï¼ˆä½ ä¹‹å‰çš„ä¹ æƒ¯ï¼‰
        if "ç³–æµ†" in name:
            return True
    
        # 2) å•ä½æ˜ç¡®æ˜¯ç™¾åˆ†æ¯”
        if unit in {"%", "ï¼…", "ç™¾åˆ†æ¯”", "percent", "ratio"}:
            return True
    
        # 3) ç»Ÿè®¡è¡¨é‡Œå¤šæ•°ç™¾åˆ†æ¯”è¡Œå•ä½æ˜¯ç©ºä¸²ï¼›å…è®¸ç»Ÿè®¡æº¢å‡ºåˆ° 150%ï¼ˆ1.5ï¼‰
        if unit == "" and pd.notna(last_rem) and 0.0 <= float(last_rem) <= 1.5:
            return True

        return False

    def _unit_norm(u: str) -> str:
        """å•ä½ç»Ÿä¸€ï¼šå»ç©ºæ ¼ã€å°å†™ã€‚"""
        return str(u or "").strip().lower()
    
    def badge_row(row: pd.Series) -> str:
        # ===== é¥®å“ç±»ä¼˜å…ˆè§„åˆ™ =====
        if str(row.get("ç±»å‹", "")).strip() == "é¥®å“ç±»":
            unit = _unit_norm(row.get("å•ä½ (Unit)"))
            cur = pd.to_numeric(row.get("å½“å‰åº“å­˜"), errors="coerce")
    
            if pd.notna(cur):
                s = float(cur)
                # å•ä½æ˜¯â€œç®±â€æ—¶ï¼Œå°äº 2 æŠ¥è­¦
                if unit in {"ç®±", "box"} and s < 2:
                    return "ğŸš¨ ç«‹å³ä¸‹å•"
                # å•ä½æ˜¯â€œç“¶â€æˆ–â€œè¢‹â€æ—¶ï¼Œå°äº 6 æŠ¥è­¦
                if unit in {"ç“¶", "è¢‹", "bottle", "bag"} and s < 6:
                    return "ğŸš¨ ç«‹å³ä¸‹å•"
            # é¥®å“ç±»ä½†ä¸ç¬¦åˆä¸Šé¢ä¸¤ä¸ªæ¡ä»¶ -> èµ°é€šç”¨è§„åˆ™ç»§ç»­åˆ¤æ–­
    
        # ===== é€šç”¨è§„åˆ™ï¼ˆéé¥®å“ç±»ï¼Œæˆ–é¥®å“ç±»æœªè§¦å‘ä¸Šé¢çš„é˜ˆå€¼ï¼‰=====
        # 1) ç™¾åˆ†æ¯”ç‰©æ–™ï¼šæœ€è¿‘å‰©ä½™æ•°é‡ < 20% æŠ¥è­¦
        if _is_percent_row(row):
            val = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
            if pd.notna(val) and float(val) < 0.2:
                return "ğŸš¨ ç«‹å³ä¸‹å•"
            return "ğŸŸ¢ æ­£å¸¸"
    
        # 2) éç™¾åˆ†æ¯”ï¼šé¢„è®¡è¿˜èƒ½ç”¨å¤©æ•° < 3 å¤© æŠ¥è­¦
        days = pd.to_numeric(row.get("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"), errors="coerce")
        if pd.notna(days) and float(days) < 3:
            return "ğŸš¨ ç«‹å³ä¸‹å•"
        return "ğŸŸ¢ æ­£å¸¸"

    stats["åº“å­˜é¢„è­¦"] = stats.apply(badge_row, axis=1) if not stats.empty else ""

    # â€”â€” åœ¨å›ºå®šé¡ºåºä¸‹æ’åºï¼ˆåªæŒ‰ __order__ï¼›mergesort ä¿æŒç¨³å®šï¼‰
    stats_sorted = stats.sort_values("__order__", kind="mergesort")

    # KPIï¼ˆç”¨æ’åºåçš„ç»“æœï¼‰
    c1, = st.columns(1)
    total_items = int(stats_sorted["é£Ÿæåç§° (Item Name)"].nunique()) if not stats_sorted.empty else 0
    c1.metric("è®°å½•æ•°é‡", value=total_items)

    # ç»“æœè¡¨
    display_cols = [
        "é£Ÿæåç§° (Item Name)", "å½“å‰åº“å­˜", "å•ä½ (Unit)", "å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡",
        "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "æœ€è¿‘ç»Ÿè®¡å‰©ä½™æ—¥æœŸ", "æœ€è¿‘é‡‡è´­æ—¥æœŸ",
        "æœ€è¿‘é‡‡è´­æ•°é‡", "æœ€è¿‘é‡‡è´­å•ä»·", "å¹³å‡é‡‡è´­é—´éš”(å¤©)", "ç´¯è®¡æ”¯å‡º", "åº“å­˜é¢„è­¦"
    ]
    show = stats_sorted[[c for c in display_cols if c in stats_sorted.columns]].copy()

    if show.empty:
        st.info("æš‚æ— ç»Ÿè®¡ç»“æœã€‚è¯·æ£€æŸ¥ã€è´­å…¥/å‰©ä½™ã€è¡¨çš„è¡¨å¤´/æ•°æ®æ˜¯å¦å®Œæ•´ã€‚")
    render_centered_table(show)

    # ============ ä¸‹é’»ï¼šç‰©å“è¯¦æƒ… ============
    st.markdown("### ğŸ” ç‰©å“è¯¦æƒ…")
    detail_items = ["ï¼ˆä¸é€‰ï¼‰"] + (list(show["é£Ÿæåç§° (Item Name)"].dropna().unique()) if "é£Ÿæåç§° (Item Name)" in show.columns else [])
    picked = st.selectbox("é€‰æ‹©ä¸€ä¸ªç‰©å“æŸ¥çœ‹è¯¦æƒ…", detail_items, index=0)

    if picked and picked != "ï¼ˆä¸é€‰ï¼‰":
        # ç»Ÿä¸€å£å¾„çš„â€œå½“å‰åº“å­˜â€ = æœ€åä¸€æ¬¡å‰©ä½™ + ä¹‹åä¹°å…¥
        item_df = normalize_columns_compute(df[df["é£Ÿæåç§° (Item Name)"] == picked].copy())
        item_df = item_df.reset_index(drop=False).rename(columns={"index": "__orig_idx__"})
        if "row_order" not in item_df.columns:
            item_df["row_order"] = item_df["__orig_idx__"]
        item_df = item_df.sort_values(["æ—¥æœŸ (Date)", "row_order"])

        rem = item_df[item_df.get("çŠ¶æ€ (Status)") == "å‰©ä½™"].copy()
        buy = item_df[item_df.get("çŠ¶æ€ (Status)") == "ä¹°å…¥"].copy()

        if len(rem):
            last_rem = rem.iloc[-1]
            last_date = last_rem["æ—¥æœŸ (Date)"]
            last_ord  = last_rem["row_order"]
            last_qty  = float(last_rem["æ•°é‡ (Qty)"]) if pd.notna(last_rem["æ•°é‡ (Qty)"]) else 0.0
            mask_after = (
                (item_df["æ—¥æœŸ (Date)"] > last_date) |
                ((item_df["æ—¥æœŸ (Date)"] == last_date) & (item_df["row_order"] > last_ord))
            )
            buys_after = item_df[mask_after & (item_df["çŠ¶æ€ (Status)"] == "ä¹°å…¥")]
            cur_stock = float(last_qty + buys_after["æ•°é‡ (Qty)"].sum())
        else:
            cur_stock = float(buy["æ•°é‡ (Qty)"].sum()) if len(buy) else float("nan")

        last_buy = buy.iloc[-1] if len(buy) else None
        last_buy_date = (last_buy["æ—¥æœŸ (Date)"].date().isoformat()
                         if last_buy is not None and pd.notna(last_buy["æ—¥æœŸ (Date)"]) else "â€”")
        last_buy_qty  = float(last_buy["æ•°é‡ (Qty)"]) if last_buy is not None else np.nan
        last_buy_price = float(last_buy["å•ä»· (Unit Price)"]) if (last_buy is not None and "å•ä»· (Unit Price)" in item_df.columns) else np.nan

        use14 = _recent_usage_14d_new(item_df)
        days_left = (cur_stock / (use14 / 14.0)) if (use14 and use14 > 0 and not np.isnan(cur_stock)) else np.nan
        stockout_date = (pd.Timestamp.today().normalize() + pd.Timedelta(days=float(days_left))).date().isoformat() \
                        if days_left == days_left else "â€”"

        if len(buy) >= 2:
            avg_interval = buy["æ—¥æœŸ (Date)"].diff().dt.days.dropna().mean()
        else:
            avg_interval = np.nan

        # KPI
        k1, k2, k3, k4, k5, k6 = st.columns(6)
        k1.metric("å½“å‰åº“å­˜", f"{0 if np.isnan(cur_stock) else cur_stock}")
        k2.metric("æœ€è¿‘14å¤©ç”¨é‡", f"{0 if not use14 else round(use14, 2)}")
        k3.metric("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "â€”" if np.isnan(days_left) else f"{days_left:.2f}")
        k4.metric("é¢„è®¡ç¼ºè´§æ—¥æœŸ", stockout_date)
        k5.metric("æœ€è¿‘é‡‡è´­æ—¥æœŸ", last_buy_date)
        k6.metric("å¹³å‡é‡‡è´­é—´éš”(å¤©)", "â€”" if np.isnan(avg_interval) else f"{avg_interval:.1f}")

        # åº“å­˜è½¨è¿¹ï¼ˆè¿‘60å¤©ï¼‰
        lookback = pd.Timestamp.today().normalize() - pd.Timedelta(days=60)
        rem60 = rem[rem["æ—¥æœŸ (Date)"] >= lookback].copy()
        if not rem60.empty:
            rem60["dt"] = pd.to_datetime(rem60["æ—¥æœŸ (Date)"])
            chart_stock = alt.Chart(rem60).mark_line(point=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q", title="å‰©ä½™æ•°é‡")
            ).properties(title=f"{picked} â€” å‰©ä½™æ•°é‡ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_stock, use_container_width=True)

        # äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰
        ev = item_df[item_df["æ—¥æœŸ (Date)"] >= lookback][["æ—¥æœŸ (Date)", "çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä»· (Unit Price)"]].copy()
        if not ev.empty:
            ev["dt"] = pd.to_datetime(ev["æ—¥æœŸ (Date)"])
            status_color = alt.Color(
                "çŠ¶æ€ (Status):N",
                scale=alt.Scale(domain=["ä¹°å…¥", "å‰©ä½™"], range=["#1f77b4", "#E4572E"]),
                legend=alt.Legend(title="çŠ¶æ€")
            )
            chart_ev = alt.Chart(ev).mark_point(filled=True, size=80).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q"),
                color=status_color,
                shape="çŠ¶æ€ (Status):N",
                tooltip=["çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä»· (Unit Price)", "æ—¥æœŸ (Date)"]
            ).properties(title=f"{picked} â€” äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_ev, use_container_width=True)

        # æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰
        st.markdown("â€ƒ")
        st.markdown("#### æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰")
        cols = ["æ—¥æœŸ (Date)", "çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä½ (Unit)", "å•ä»· (Unit Price)", "æ€»ä»· (Total Cost)", "åˆ†ç±» (Category)", "å¤‡æ³¨ (Notes)"]
        cols = [c for c in cols if c in item_df.columns]
        st.dataframe(item_df[cols].sort_values("æ—¥æœŸ (Date)").iloc[::-1].head(10), use_container_width=True)
