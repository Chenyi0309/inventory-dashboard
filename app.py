# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

# ================= Secrets/ENV =================
# å°† service account å†™å…¥æœ¬åœ°ï¼Œä¾› gspread ä½¿ç”¨
if "service_account" in st.secrets:
    with open("service_account.json", "w") as f:
        json.dump(dict(st.secrets["service_account"]), f)

# è¯»å– Sheet URLï¼ˆsecrets ä¼˜å…ˆç”Ÿæ•ˆï¼‰
sheet_url = st.secrets.get("INVENTORY_SHEET_URL", None) or os.getenv("INVENTORY_SHEET_URL", None)
if sheet_url:
    os.environ["INVENTORY_SHEET_URL"] = sheet_url

# ================ Backend ======================
# è¯»å†™ Google Sheet
from gsheet import append_records_bulk
try:
    from gsheet import read_records_cached as read_records_fn, read_catalog_cached as read_catalog_fn, bust_cache
except Exception:
    from gsheet import read_records as read_records_fn, read_catalog as read_catalog_fn
    def bust_cache(): pass

# ç»Ÿè®¡è®¡ç®—/åˆ—åè§„èŒƒåŒ–
try:
    from compute import compute_stats, _recent_usage_14d_robust as _recent_usage_14d_new, normalize_columns as normalize_columns_compute
except Exception:
    from compute import compute_stats, _recent_usage_14d_new
    def normalize_columns_compute(df: pd.DataFrame) -> pd.DataFrame:
        return df

# å…è®¸çš„å››ä¸ªç±»åˆ«ï¼ˆç¡¬ç¼–ç ï¼‰
ALLOWED_CATS = ["é£Ÿç‰©ç±»", "æ¸…æ´ç±»", "æ¶ˆè€—å“", "é¥®å“ç±»"]
DEFAULT_CAT = "é£Ÿç‰©ç±»"


# ============== ä»…ç”¨äºå½•å…¥é¡µçš„è½»é‡å·¥å…· ==============
def safe_sort(df: pd.DataFrame, by: str, ascending=True):
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def normalize_cat(x: str) -> str:
    if x is None:
        return DEFAULT_CAT
    s = str(x).strip()
    if s == "" or s.lower() in ("nan", "none"):
        return DEFAULT_CAT
    return s if s in ALLOWED_CATS else DEFAULT_CAT

def _blank_if_none(x):
    try:
        if x is None or (isinstance(x, float) and pd.isna(x)):
            return ""
    except Exception:
        pass
    return x

def parse_qty_with_percent(raw, unit):
    """æŠŠæ•°é‡é‡Œå¸¦ % çš„è¾“å…¥æˆ–å•ä½ä¸º % çš„è¾“å…¥ï¼Œç»Ÿä¸€è½¬æ¢æˆ 0~1 çš„å°æ•°ï¼Œå¹¶æŠŠå•ä½æ ‡å‡†åŒ–ä¸º '%'ã€‚"""
    unit_norm = (unit or "").replace("ï¼…", "%").strip()
    s = str(raw).strip() if raw is not None else ""

    # 1) æ•°é‡é‡Œè‡ªå¸¦ç™¾åˆ†å·ï¼Œå¦‚ '20%'
    if s.endswith("%"):
        num = pd.to_numeric(s[:-1], errors="coerce")
        return (float(num) / 100.0 if pd.notna(num) else np.nan), "%"

    # 2) å•ä½æ˜¯ç™¾åˆ†å·
    if unit_norm in {"%", "ç™¾åˆ†æ¯”", "percent", "ratio"}:
        num = pd.to_numeric(s, errors="coerce")
        if pd.isna(num):
            return np.nan, "%"
        num = float(num)
        return (num / 100.0 if num > 1 else num), "%"

    # 3) æ™®é€šæ•°é‡
    return pd.to_numeric(s, errors="coerce"), unit_norm


# ================ APP UI =======================
st.set_page_config(page_title="Gangnam åº“å­˜ç®¡ç†", layout="wide")

# é¡¶éƒ¨å¸ƒå±€ï¼šå·¦è¾¹ logoï¼Œå³è¾¹æ ‡é¢˜è¯´æ˜
c1, c2 = st.columns([1, 6])
with c1:
    st.image("gangnam_logo.png", width=180)

with c2:
    st.markdown(
        """
        <div style="display:flex; flex-direction:column; justify-content:center; height:100%;">
            <h1 style="margin-bottom:0;">Gangnam åº“å­˜ç®¡ç†</h1>
            <p style="color:gray; font-size:16px; margin-top:4px;">
                å½•å…¥â€˜ä¹°å…¥/å‰©ä½™â€™ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°è¡¨æ ¼ï¼Œå¹¶å®æ—¶ç”Ÿæˆâ€˜åº“å­˜ç»Ÿè®¡â€™åˆ†æ
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )

tabs = st.tabs(["â• å½•å…¥è®°å½•", "ğŸ“Š åº“å­˜ç»Ÿè®¡"])


# ================== å½•å…¥è®°å½• ==================
with tabs[0]:
    st.subheader("å½•å…¥æ–°è®°å½•")

    # è¯»å–â€œè´­å…¥/å‰©ä½™â€ç”¨äºæ¨æ–­å·²æœ‰ç‰©å“ï¼ˆå½“æ²¡æœ‰ä¸»æ•°æ®æ—¶ï¼‰
    try:
        df_all = read_records_fn()
        df_all = normalize_columns_compute(df_all)  # ä½¿ç”¨ compute çš„å¼ºåŠ›æ¸…æ´—
    except Exception:
        df_all = pd.DataFrame()

    # ä¸»æ•°æ®ï¼ˆåº“å­˜äº§å“ï¼‰
    try:
        catalog = read_catalog_fn()
    except Exception:
        catalog = pd.DataFrame()

    c1, c2, c3 = st.columns(3)
    sel_date   = c1.date_input("æ—¥æœŸ (Date)", pd.Timestamp.today())
    sel_type   = c2.selectbox("ç±»å‹ï¼ˆå¤§ç±»ï¼‰", ALLOWED_CATS, index=0)
    sel_status = c3.selectbox("çŠ¶æ€ (Status)", ["ä¹°å…¥", "å‰©ä½™"])

    # æ„é€ å¯ç¼–è¾‘è¡¨ï¼šä¼˜å…ˆä¸»æ•°æ®ï¼Œå¦åˆ™å†å²è®°å½•ä¸­è¯¥ç±»çš„æœ€è¿‘å•ä½
    if not catalog.empty and {"ç‰©å“å", "å•ä½", "ç±»å‹"}.issubset(catalog.columns):
        catalog = catalog.copy()
        catalog["ç±»å‹"] = catalog["ç±»å‹"].apply(normalize_cat)
        base = (catalog[catalog["ç±»å‹"] == sel_type][["ç‰©å“å", "å•ä½"]]
                .drop_duplicates()
                .reset_index(drop=True))
    else:
        if not df_all.empty:
            tmp = df_all.copy()
            if "åˆ†ç±» (Category)" not in tmp.columns:
                tmp["åˆ†ç±» (Category)"] = DEFAULT_CAT
            tmp["åˆ†ç±» (Category)"] = tmp["åˆ†ç±» (Category)"].apply(normalize_cat)
            latest_unit = (
                safe_sort(tmp[tmp["åˆ†ç±» (Category)"] == sel_type], "æ—¥æœŸ (Date)")
                .groupby("é£Ÿæåç§° (Item Name)")["å•ä½ (Unit)"]
                .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else "")
                .reset_index()
                .rename(columns={"é£Ÿæåç§° (Item Name)": "ç‰©å“å", "å•ä½ (Unit)": "å•ä½"})
            )
            base = latest_unit
        else:
            base = pd.DataFrame(columns=["ç‰©å“å", "å•ä½"])

        # ---------- æ„é€ å¯ç¼–è¾‘è¡¨ ----------
        edit_df = base.copy()
        for col in ["ç‰©å“å", "å•ä½"]:
            if col not in edit_df.columns:
                edit_df[col] = ""
        
        # ç”¨å­—ç¬¦ä¸²å ä½ï¼Œä¾¿äº TextColumn æ¥å— '20%' è¿™ç±»è¾“å…¥
        edit_df["æ•°é‡"] = ""
        if sel_status == "ä¹°å…¥":
            edit_df["å•ä»·"] = np.nan
        edit_df["å¤‡æ³¨"] = ""
        
        st.markdown("**åœ¨ä¸‹è¡¨ä¸­å¡«å†™æ•°é‡ï¼ˆå¿…å¡«ï¼‰ï¼Œå•ä»·ä»…åœ¨ä¹°å…¥æ—¶å¡«å†™ï¼›å¯æ·»åŠ æ–°è¡Œå½•å…¥æ–°ç‰©å“**")

        edited = st.data_editor(
            # æ˜ç¡®æŠŠâ€œæ•°é‡â€åˆ—è®¾æˆ object/str
            edit_df.astype({"æ•°é‡": "object"}),
            use_container_width=True,
            num_rows="dynamic",
            column_config={
                # åˆ é™¤ placeholderï¼Œä¿ç•™ä¸€ä¸ªç®€å•çš„å¸®åŠ©æç¤º
                "æ•°é‡": st.column_config.TextColumn(help="æ”¯æŒè¾“å…¥ 3ã€0.5 æˆ– 20%"),
                "å•ä»·": (
                    st.column_config.NumberColumn(step=0.01, min_value=0.0)
                    if sel_status == "ä¹°å…¥" else None
                ),
            },
            key="bulk_editor",
        )

    # æ‰¹é‡å†™å…¥ Google Sheet
    if st.button("âœ… æ‰¹é‡ä¿å­˜åˆ°ã€è´­å…¥/å‰©ä½™ã€"):
        # 1) é€è¡Œè§£æï¼ˆæ”¯æŒç™¾åˆ†æ¯”ï¼‰ï¼Œå¹¶åšæ ¡éªŒä¸æ¸…æ´—
        rows_raw = edited.copy()

        valid_rows = []
        for _, r in rows_raw.iterrows():
            name = str(r.get("ç‰©å“å", "")).strip()
            if not name:
                continue

            unit_in = str(r.get("å•ä½", "") or "").strip()
            qty, unit_norm = parse_qty_with_percent(r.get("æ•°é‡", ""), unit_in)

            # æ•°é‡å¿…é¡»æ˜¯æ•°å€¼ï¼›ä¹°å…¥>0ï¼›å‰©ä½™>=0ï¼ˆå…è®¸è®°å½• 0ï¼‰
            if pd.isna(qty):
                continue
            qf = float(qty)
            if sel_status == "ä¹°å…¥":
                if qf <= 0:
                    continue
            else:  # å‰©ä½™
                if qf < 0:
                    continue

            row_clean = {
                "ç‰©å“å": name,
                "å•ä½": unit_norm,
                "æ•°é‡": qf,
                "å¤‡æ³¨": str(r.get("å¤‡æ³¨", "") or "").strip(),
            }

            if sel_status == "ä¹°å…¥":
                price = pd.to_numeric(r.get("å•ä»·", ""), errors="coerce")
                row_clean["å•ä»·"] = float(price) if pd.notna(price) else None

            valid_rows.append(row_clean)

        if not valid_rows:
            st.warning("è¯·è‡³å°‘å¡«å†™ä¸€ä¸ªç‰©å“çš„â€˜ç‰©å“åâ€™å’Œâ€˜æ•°é‡â€™ï¼ˆä¹°å…¥>0ï¼›å‰©ä½™å¯=0ï¼‰")
            st.stop()

        # 2) æ„é€  payload + é¢„è§ˆ
        dt = pd.to_datetime(sel_date)
        payload = []
        preview = []

        for rr in valid_rows:
            qty  = rr["æ•°é‡"]
            unit = rr["å•ä½"]
            price = rr.get("å•ä»·", None)
            total = round(qty * price, 2) if (sel_status == "ä¹°å…¥" and price is not None) else None

            record = {
                "æ—¥æœŸ (Date)": f"=DATE({dt.year},{dt.month},{dt.day})",
                "é£Ÿæåç§° (Item Name)": rr["ç‰©å“å"],
                "åˆ†ç±» (Category)": sel_type,
                "æ•°é‡ (Qty)": qty,
                "å•ä½ (Unit)": unit,
                "å•ä»· (Unit Price)": "" if price is None else price,
                "æ€»ä»· (Total Cost)": "" if total is None else total,
                "çŠ¶æ€ (Status)": sel_status,
                "å¤‡æ³¨ (Notes)": rr["å¤‡æ³¨"],
            }
            payload.append(record)

            # é¢„è§ˆï¼šç™¾åˆ†æ¯”æ˜¾ç¤ºä¸º 20%
            display_qty = f"{round(qty*100, 2)}%" if unit == "%" else qty
            row_preview = {
                "æ—¥æœŸ": dt.date().isoformat(),
                "ç‰©å“å": rr["ç‰©å“å"],
                "æ•°é‡": display_qty,
                "å•ä½": unit,
                "çŠ¶æ€": sel_status,
            }
            if sel_status == "ä¹°å…¥":
                row_preview["å•ä»·"] = "" if price is None else price
                row_preview["æ€»ä»·"] = "" if total is None else total
            preview.append(row_preview)

        # 3) æ‰¹é‡å†™å…¥ + æ˜¾ç¤ºå†™å…¥æ˜ç»† + å›è¯»æ ¡éªŒ
        try:
            if payload:
                resp = append_records_bulk(payload)  # gsheet å†…éƒ¨å·²ç”¨ USER_ENTERED + table_range="A1"
                st.success(f"å·²æˆåŠŸå†™å…¥ {len(payload)} æ¡è®°å½•ï¼")
                st.caption(f"ç›®æ ‡è¡¨ï¼š{st.secrets.get('INVENTORY_SHEET_URL') or os.getenv('INVENTORY_SHEET_URL')}")

                # æ˜¾ç¤º Google è¿”å›çš„å†™å…¥åŒºé—´ï¼ˆç”¨äºå®šä½åˆ°åº•å†™åˆ°å“ªä¸€æ®µï¼‰
                from gsheet import parse_updated_range_rows, tail_rows
                rng = resp.get("updates", {}).get("updatedRange", "")
                st.caption(f"Google è¿”å›å†™å…¥åŒºé—´ï¼š{rng}")
                rows_info = parse_updated_range_rows(resp)
                if rows_info:
                    st.caption(f"ï¼ˆèµ·æ­¢è¡Œå·ï¼š{rows_info[0]}â€“{rows_info[1]}ï¼‰")

                # è¡¨å°¾å¿«ç…§
                with st.expander("ğŸ” è¡¨å°¾å¿«ç…§ï¼ˆæœ€è¿‘ 10 è¡Œï¼‰", expanded=False):
                    st.dataframe(tail_rows(10), use_container_width=True)

                # æœ¬æ¬¡å†™å…¥çš„è®°å½•ï¼ˆé¢„è§ˆï¼‰
                pre_df = pd.DataFrame(preview)
                if sel_status == "ä¹°å…¥":
                    pre_df = pre_df[["æ—¥æœŸ", "ç‰©å“å", "æ•°é‡", "å•ä½", "å•ä»·", "æ€»ä»·", "çŠ¶æ€"]]
                    with pd.option_context("mode.use_inf_as_na", True):
                        total_spent = pd.to_numeric(pre_df.get("æ€»ä»·"), errors="coerce").sum()
                    st.caption(f"æœ¬æ¬¡ä¹°å…¥åˆè®¡é‡‘é¢ï¼š{total_spent:.2f}")
                else:
                    pre_df = pre_df[["æ—¥æœŸ", "ç‰©å“å", "æ•°é‡", "å•ä½", "çŠ¶æ€"]]
                st.markdown("**æœ¬æ¬¡å†™å…¥çš„è®°å½•**")
                st.dataframe(pre_df, use_container_width=True)

                # å›è¯»æ ¡éªŒ
                try:
                    bust_cache()
                except Exception:
                    pass
                try:
                    df_check = read_records_fn()
                    df_check = normalize_columns_compute(df_check)
                    dd = pd.to_datetime(df_check.get("æ—¥æœŸ (Date)"), errors="coerce").dt.date
                    names = [p["ç‰©å“å"] for p in preview]
                    just_now = df_check[
                        (dd == dt.date()) &
                        (df_check.get("çŠ¶æ€ (Status)") == sel_status) &
                        (df_check.get("é£Ÿæåç§° (Item Name)").isin(names))
                    ][["æ—¥æœŸ (Date)","é£Ÿæåç§° (Item Name)","æ•°é‡ (Qty)","çŠ¶æ€ (Status)"]].copy()
                    st.markdown("**å†™å…¥åçš„å›è¯»æ ¡éªŒ**")
                    if just_now.empty:
                        st.warning("è¡¨é‡Œæš‚æœªè¯»åˆ°åˆšå†™å…¥çš„è¡Œï¼ˆå¯èƒ½è¢«è¡¨æ ¼æ ¼å¼/åº•éƒ¨ç©ºç™½åŒºåŸŸå½±å“ï¼‰ã€‚è‹¥ä»æœªå‡ºç°ï¼Œè¯·æ¸…ç†è¡¨åº•éƒ¨å¤šä½™æ ¼å¼ï¼Œå¹¶ç¡®è®¤ gsheet.append ä½¿ç”¨ USER_ENTERED + table_range='A1'ã€‚")
                    else:
                        st.dataframe(just_now.sort_values("æ—¥æœŸ (Date)"), use_container_width=True)
                except Exception:
                    pass

            else:
                st.info("æ²¡æœ‰å¯å†™å…¥çš„è®°å½•ã€‚")
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")


# ================== åº“å­˜ç»Ÿè®¡ ==================
with tabs[1]:
    st.subheader("åº“å­˜ç»Ÿè®¡")

    colR1, _ = st.columns([1, 3])
    if colR1.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è¯»å– Google Sheet"):
        try:
            bust_cache()
        except Exception:
            pass
        st.rerun()

    # è¯»æ˜ç»†å¹¶ç»Ÿä¸€åˆ—å â€”â€” ä½¿ç”¨ compute çš„è§„èŒƒåŒ–
    try:
        df = read_records_fn()
        df = normalize_columns_compute(df)
    except Exception as e:
        st.error(f"è¯»å–è¡¨æ ¼å¤±è´¥ï¼š{e}")
        st.stop()

    # è°ƒè¯•é¢æ¿ï¼šçœ‹çœ‹å®é™…è¯»åˆ°äº†ä»€ä¹ˆ
    with st.expander("ğŸ” è°ƒè¯•ï¼šæŸ¥çœ‹åŸå§‹æ•°æ®å¿«ç…§", expanded=False):
        st.write("shape:", df.shape)
        st.write("columns:", list(df.columns))
        for col in ["æ—¥æœŸ (Date)", "é£Ÿæåç§° (Item Name)", "åˆ†ç±» (Category)", "çŠ¶æ€ (Status)"]:
            if col in df.columns:
                st.write(f"{col} éç©ºæ•°é‡:", int(df[col].notna().sum()))
            else:
                st.write(f"âš ï¸ æœªè¯†åˆ«åˆ—ï¼š{col}")
        if not df.empty:
            st.dataframe(df.head(10), use_container_width=True)

    # å…œåº•åˆ†ç±»
    if "åˆ†ç±» (Category)" not in df.columns:
        df["åˆ†ç±» (Category)"] = DEFAULT_CAT
    else:
        df["åˆ†ç±» (Category)"] = df["åˆ†ç±» (Category)"].apply(normalize_cat)

    # ç»Ÿè®¡è¡¨
    stats_all = compute_stats(df)

    # â€œç±»å‹â€åˆ—ç”¨äºç­›é€‰
    if not df.empty and "é£Ÿæåç§° (Item Name)" in df.columns:
        latest_cat = (
            df.sort_values("æ—¥æœŸ (Date)")
            .groupby("é£Ÿæåç§° (Item Name)")["åˆ†ç±» (Category)"]
            .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else DEFAULT_CAT)
        )
        stats_all = stats_all.merge(
            latest_cat.rename("ç±»å‹"),
            left_on="é£Ÿæåç§° (Item Name)", right_index=True, how="left"
        )
    else:
        stats_all["ç±»å‹"] = DEFAULT_CAT
    stats_all["ç±»å‹"] = stats_all["ç±»å‹"].apply(normalize_cat)

    # === ç­›é€‰æ¡ï¼ˆä½œç”¨äºä¸‹æ–¹ç»“æœè¡¨ï¼‰ ===
    st.markdown("#### ç­›é€‰")
    fc1, _ = st.columns([1, 3])
    sel_type_bar = fc1.selectbox("é€‰æ‹©åˆ†ç±»", ["å…¨éƒ¨"] + ALLOWED_CATS, index=0)
    stats = stats_all.copy() if sel_type_bar == "å…¨éƒ¨" else stats_all[stats_all["ç±»å‹"].eq(sel_type_bar)].copy()

    # é¢„è­¦ï¼šæ™®é€š<5ï¼›ç™¾åˆ†æ¯”/ç³–æµ†<20%
    def _is_percent_row(row: pd.Series) -> bool:
        name = str(row.get("é£Ÿæåç§° (Item Name)", "") or "")
        unit = str(row.get("å•ä½ (Unit)", "") or "").strip()
        last_rem = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
        if "ç³–æµ†" in name:
            return True
        if unit in ["%", "ï¼…", "ç™¾åˆ†æ¯”", "percent", "ratio"]:
            return True
        if pd.notna(last_rem) and 0.0 <= float(last_rem) <= 1.0:
            return True
        return False

    def badge_row(row: pd.Series) -> str:
        if _is_percent_row(row):
            val = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
            if pd.notna(val) and float(val) < 0.2:
                return "ğŸš¨ ç«‹å³ä¸‹å•"
            return "ğŸŸ¢ æ­£å¸¸"
        else:
            val = pd.to_numeric(row.get("å½“å‰åº“å­˜"), errors="coerce")
            if pd.notna(val) and float(val) < 5:
                return "ğŸš¨ ç«‹å³ä¸‹å•"
            return "ğŸŸ¢ æ­£å¸¸"

    if not stats.empty:
        stats["åº“å­˜é¢„è­¦"] = stats.apply(badge_row, axis=1)
    else:
        stats["åº“å­˜é¢„è­¦"] = ""

    # ä»…ä¿ç•™ä¸€ä¸ª KPIï¼šè®°å½•æ•°é‡
    c1, = st.columns(1)
    total_items = int(stats["é£Ÿæåç§° (Item Name)"].nunique()) if not stats.empty and "é£Ÿæåç§° (Item Name)" in stats.columns else 0
    c1.metric("è®°å½•æ•°é‡", value=total_items)

    # ç»“æœè¡¨
    display_cols = [
        "é£Ÿæåç§° (Item Name)", "å½“å‰åº“å­˜", "å•ä½ (Unit)", "å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡",
        "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "æœ€è¿‘ç»Ÿè®¡å‰©ä½™æ—¥æœŸ", "æœ€è¿‘é‡‡è´­æ—¥æœŸ",
        "æœ€è¿‘é‡‡è´­æ•°é‡", "æœ€è¿‘é‡‡è´­å•ä»·", "å¹³å‡é‡‡è´­é—´éš”(å¤©)", "ç´¯è®¡æ”¯å‡º", "åº“å­˜é¢„è­¦"
    ]
    show = stats[[c for c in display_cols if c in stats.columns]].copy()

    # æ’åºï¼šæŒ‰é¢„è­¦ä¸¥é‡&è¿˜èƒ½ç”¨å¤©æ•°
    severity = {"ğŸš¨ ç«‹å³ä¸‹å•": 0, "ğŸŸ¢ æ­£å¸¸": 2, "": 3}
    if "åº“å­˜é¢„è­¦" in show.columns:
        show["__sev__"] = show["åº“å­˜é¢„è­¦"].map(severity).fillna(3)
        if "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°" in show.columns:
            show = show.sort_values(["__sev__", "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"], ascending=[True, True])
        show = show.drop(columns="__sev__", errors="ignore")

    if show.empty:
        st.info("æš‚æ— ç»Ÿè®¡ç»“æœã€‚è¯·æ£€æŸ¥ã€è´­å…¥/å‰©ä½™ã€è¡¨çš„è¡¨å¤´/æ•°æ®æ˜¯å¦å®Œæ•´ã€‚")
    st.dataframe(show, use_container_width=True)

    # å¯¼å‡º
    csv = show.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ å¯¼å‡ºç»Ÿè®¡ç»“æœï¼ˆCSVï¼‰", data=csv, file_name="inventory_stats.csv", mime="text/csv")

    # ============ ä¸‹é’»ï¼šç‰©å“è¯¦æƒ… ============
    st.markdown("### ğŸ” ç‰©å“è¯¦æƒ…")
    detail_items = ["ï¼ˆä¸é€‰ï¼‰"] + (list(show["é£Ÿæåç§° (Item Name)"].dropna().unique()) if "é£Ÿæåç§° (Item Name)" in show.columns else [])
    picked = st.selectbox("é€‰æ‹©ä¸€ä¸ªç‰©å“æŸ¥çœ‹è¯¦æƒ…", detail_items, index=0)

    if picked and picked != "ï¼ˆä¸é€‰ï¼‰":
        # ç»Ÿä¸€å£å¾„çš„â€œå½“å‰åº“å­˜â€ = æœ€åä¸€æ¬¡å‰©ä½™ + ä¹‹åä¹°å…¥
        item_df = normalize_columns_compute(df[df["é£Ÿæåç§° (Item Name)"] == picked].copy())
        item_df = item_df.reset_index(drop=False).rename(columns={"index": "__orig_idx__"})
        if "row_order" not in item_df.columns:
            item_df["row_order"] = item_df["__orig_idx__"]
        item_df = item_df.sort_values(["æ—¥æœŸ (Date)", "row_order"])

        rem = item_df[item_df.get("çŠ¶æ€ (Status)") == "å‰©ä½™"].copy()
        buy = item_df[item_df.get("çŠ¶æ€ (Status)") == "ä¹°å…¥"].copy()

        if len(rem):
            last_rem = rem.iloc[-1]
            last_date = last_rem["æ—¥æœŸ (Date)"]
            last_ord  = last_rem["row_order"]
            last_qty  = float(last_rem["æ•°é‡ (Qty)"]) if pd.notna(last_rem["æ•°é‡ (Qty)"]) else 0.0
            mask_after = (
                (item_df["æ—¥æœŸ (Date)"] > last_date) |
                ((item_df["æ—¥æœŸ (Date)"] == last_date) & (item_df["row_order"] > last_ord))
            )
            buys_after = item_df[mask_after & (item_df["çŠ¶æ€ (Status)"] == "ä¹°å…¥")]
            cur_stock = float(last_qty + buys_after["æ•°é‡ (Qty)"].sum())
        else:
            cur_stock = float(buy["æ•°é‡ (Qty)"].sum()) if len(buy) else float("nan")

        last_buy = buy.iloc[-1] if len(buy) else None
        last_buy_date = (last_buy["æ—¥æœŸ (Date)"].date().isoformat()
                         if last_buy is not None and pd.notna(last_buy["æ—¥æœŸ (Date)"]) else "â€”")
        last_buy_qty  = float(last_buy["æ•°é‡ (Qty)"]) if last_buy is not None else np.nan
        last_buy_price = float(last_buy["å•ä»· (Unit Price)"]) if (last_buy is not None and "å•ä»· (Unit Price)" in item_df.columns) else np.nan

        use14 = _recent_usage_14d_new(item_df)
        days_left = (cur_stock / (use14 / 14.0)) if (use14 and use14 > 0 and not np.isnan(cur_stock)) else np.nan
        stockout_date = (pd.Timestamp.today().normalize() + pd.Timedelta(days=float(days_left))).date().isoformat() \
                        if days_left == days_left else "â€”"

        if len(buy) >= 2:
            avg_interval = buy["æ—¥æœŸ (Date)"].diff().dt.days.dropna().mean()
        else:
            avg_interval = np.nan

        # KPI
        k1, k2, k3, k4, k5, k6 = st.columns(6)
        k1.metric("å½“å‰åº“å­˜", f"{0 if np.isnan(cur_stock) else cur_stock}")
        k2.metric("æœ€è¿‘14å¤©ç”¨é‡", f"{0 if not use14 else round(use14, 2)}")
        k3.metric("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "â€”" if np.isnan(days_left) else f"{days_left:.2f}")
        k4.metric("é¢„è®¡ç¼ºè´§æ—¥æœŸ", stockout_date)
        k5.metric("æœ€è¿‘é‡‡è´­æ—¥æœŸ", last_buy_date)
        k6.metric("å¹³å‡é‡‡è´­é—´éš”(å¤©)", "â€”" if np.isnan(avg_interval) else f"{avg_interval:.1f}")

        # åº“å­˜è½¨è¿¹ï¼ˆè¿‘60å¤©ï¼‰
        lookback = pd.Timestamp.today().normalize() - pd.Timedelta(days=60)
        rem60 = rem[rem["æ—¥æœŸ (Date)"] >= lookback].copy()
        if not rem60.empty:
            rem60["dt"] = pd.to_datetime(rem60["æ—¥æœŸ (Date)"])
            chart_stock = alt.Chart(rem60).mark_line(point=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q", title="å‰©ä½™æ•°é‡")
            ).properties(title=f"{picked} â€” å‰©ä½™æ•°é‡ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_stock, use_container_width=True)

        # äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰
        ev = item_df[item_df["æ—¥æœŸ (Date)"] >= lookback][["æ—¥æœŸ (Date)", "çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä»· (Unit Price)"]].copy()
        if not ev.empty:
            ev["dt"] = pd.to_datetime(ev["æ—¥æœŸ (Date)"])
            status_color = alt.Color(
                "çŠ¶æ€ (Status):N",
                scale=alt.Scale(
                    domain=["ä¹°å…¥", "å‰©ä½™"],
                    range=["#1f77b4", "#E4572E"]
                ),
                legend=alt.Legend(title="çŠ¶æ€")
            )
            chart_ev = alt.Chart(ev).mark_point(filled=True, size=80).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q"),
                color=status_color,
                shape="çŠ¶æ€ (Status):N",
                tooltip=["çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä»· (Unit Price)", "æ—¥æœŸ (Date)"]
            ).properties(title=f"{picked} â€” äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_ev, use_container_width=True)

        # æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰
        st.markdown("â€ƒ")
        st.markdown("#### æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰")
        cols = ["æ—¥æœŸ (Date)", "çŠ¶æ€ (Status)", "æ•°é‡ (Qty)", "å•ä½ (Unit)", "å•ä»· (Unit Price)", "æ€»ä»· (Total Cost)", "åˆ†ç±» (Category)", "å¤‡æ³¨ (Notes)"]
        cols = [c for c in cols if c in item_df.columns]
        st.dataframe(item_df[cols].sort_values("æ—¥æœŸ (Date)").iloc[::-1].head(10), use_container_width=True)
