# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

# ================= Secrets/ENV =================
if "service_account" in st.secrets:
    with open("service_account.json", "w") as f:
        json.dump(dict(st.secrets["service_account"]), f)

sheet_url = st.secrets.get("INVENTORY_SHEET_URL", None) or os.getenv("INVENTORY_SHEET_URL", None)
if sheet_url:
    os.environ["INVENTORY_SHEET_URL"] = sheet_url

# ================ Backend ======================
from gsheet import append_record
try:
    from gsheet import read_records_cached as read_records_fn, read_catalog_cached as read_catalog_fn, bust_cache
except Exception:
    from gsheet import read_records as read_records_fn, read_catalog as read_catalog_fn
    def bust_cache(): pass

try:
    from compute import compute_stats, _recent_usage_14d_robust as _recent_usage_14d_new
except Exception:
    from compute import compute_stats, _recent_usage_14d_new

# å…è®¸çš„å››ä¸ªç±»åˆ«ï¼ˆç¡¬ç¼–ç ï¼‰
ALLOWED_CATS = ["é£Ÿç‰©ç±»", "æ¸…æ´ç±»", "æ¶ˆè€—å“", "é¥®å“ç±»"]
DEFAULT_CAT = "é£Ÿç‰©ç±»"

# ============== åˆ—åå½’ä¸€åŒ– + å®‰å…¨æ’åºå·¥å…· ==============
ALIASES = {
    "æ—¥æœŸ (Date)": ["æ—¥æœŸ (Date)","æ—¥æœŸ","Date","date"],
    "é£Ÿæåç§° (Item Name)": ["é£Ÿæåç§° (Item Name)","é£Ÿæåç§°","Item Name","item name","ç‰©å“å","åç§°"],
    "åˆ†ç±» (Category)": ["åˆ†ç±» (Category)","åˆ†ç±»","Category","category","ç±»å‹"],
    "æ•°é‡ (Qty)": ["æ•°é‡ (Qty)","æ•°é‡","Qty","qty"],
    "å•ä½ (Unit)": ["å•ä½ (Unit)","å•ä½","Unit","unit"],
    "å•ä»· (Unit Price)": ["å•ä»· (Unit Price)","å•ä»·","Unit Price","price","unit price"],
    "æ€»ä»· (Total Cost)": ["æ€»ä»· (Total Cost)","æ€»ä»·","Total Cost","amount","cost"],
    "çŠ¶æ€ (Status)": ["çŠ¶æ€ (Status)","çŠ¶æ€","Status","status"],
    "å¤‡æ³¨ (Notes)": ["å¤‡æ³¨ (Notes)","å¤‡æ³¨","Notes","notes"],
}

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    df = df.rename(columns={c: str(c).strip() for c in df.columns})
    lower_map = {c.lower(): c for c in df.columns}
    mapping = {}
    for std, alts in ALIASES.items():
        for a in alts:
            if a in df.columns:
                mapping[a] = std; break
            if a.lower() in lower_map:
                mapping[lower_map[a.lower()]] = std; break
    df = df.rename(columns=mapping)
    # ç±»å‹æ¸…æ´—ï¼ˆå°½é‡æ—©åšï¼‰
    if "æ—¥æœŸ (Date)" in df.columns:
        df["æ—¥æœŸ (Date)"] = pd.to_datetime(df["æ—¥æœŸ (Date)"], errors="coerce")
    for col in ["æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ€»ä»· (Total Cost)"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def safe_sort(df: pd.DataFrame, by: str, ascending=True):
    """å¦‚æœåˆ—ä¸å­˜åœ¨å°±ç›´æ¥è¿”å›ï¼Œä¸æ’åºï¼Œé¿å… KeyErrorã€‚"""
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def normalize_cat(x: str) -> str:
    if x is None:
        return DEFAULT_CAT
    s = str(x).strip()
    if s == "" or s.lower() in ("nan","none"):
        return DEFAULT_CAT
    return s if s in ALLOWED_CATS else DEFAULT_CAT

# ================ APP UI =======================
st.set_page_config(page_title="åº“å­˜ç®¡ç† Dashboard", layout="wide")
st.title("ğŸ± åº“å­˜ç®¡ç† Dashboard")
st.caption("å½•å…¥â€˜ä¹°å…¥/å‰©ä½™â€™ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°è¡¨æ ¼ï¼Œå¹¶å®æ—¶ç”Ÿæˆâ€˜åº“å­˜ç»Ÿè®¡â€™åˆ†æ")

tabs = st.tabs(["â• å½•å…¥è®°å½•", "ğŸ“Š åº“å­˜ç»Ÿè®¡"])

# ================== å½•å…¥è®°å½• ==================
with tabs[0]:
    st.subheader("å½•å…¥æ–°è®°å½•")

    # è¯»å–â€œè´­å…¥/å‰©ä½™â€ç”¨äºæ¨æ–­å·²æœ‰ç‰©å“ï¼ˆå½“æ²¡æœ‰ä¸»æ•°æ®æ—¶ï¼‰
    try:
        df_all = read_records_fn()
        df_all = normalize_columns(df_all)
    except Exception:
        df_all = pd.DataFrame()

    # ä¸»æ•°æ®å¯é€‰
    try:
        catalog = read_catalog_fn()
    except Exception:
        catalog = pd.DataFrame()

    c1, c2, c3 = st.columns(3)
    sel_date   = c1.date_input("æ—¥æœŸ (Date)", pd.Timestamp.today())
    sel_type   = c2.selectbox("ç±»å‹ï¼ˆå¤§ç±»ï¼‰", ALLOWED_CATS, index=0)
    sel_status = c3.selectbox("çŠ¶æ€ (Status)", ["ä¹°å…¥", "å‰©ä½™"])

    # æ„é€ å¯ç¼–è¾‘è¡¨ï¼šä¼˜å…ˆä¸»æ•°æ®ï¼Œå¦åˆ™å†å²è®°å½•ä¸­è¯¥ç±»çš„æœ€è¿‘å•ä½
    if not catalog.empty and {"ç‰©å“å","å•ä½","ç±»å‹"}.issubset(catalog.columns):
        base = catalog[catalog["ç±»å‹"] == sel_type][["ç‰©å“å","å•ä½"]].drop_duplicates().reset_index(drop=True)
    else:
        if not df_all.empty:
            tmp = df_all.copy()
            if "åˆ†ç±» (Category)" not in tmp.columns:
                tmp["åˆ†ç±» (Category)"] = DEFAULT_CAT
            tmp["åˆ†ç±» (Category)"] = tmp["åˆ†ç±» (Category)"].apply(normalize_cat)
            latest_unit = (
                safe_sort(tmp[tmp["åˆ†ç±» (Category)"] == sel_type], "æ—¥æœŸ (Date)")
                .groupby("é£Ÿæåç§° (Item Name)")["å•ä½ (Unit)"]
                .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else "")
                .reset_index()
                .rename(columns={"é£Ÿæåç§° (Item Name)":"ç‰©å“å","å•ä½ (Unit)":"å•ä½"})
            )
            base = latest_unit
        else:
            base = pd.DataFrame(columns=["ç‰©å“å","å•ä½"])

    edit_df = base.copy()
    for col in ["ç‰©å“å","å•ä½"]:
        if col not in edit_df.columns: edit_df[col] = ""
    edit_df["æ•°é‡"] = 0.0
    if sel_status == "ä¹°å…¥":
        edit_df["å•ä»·"] = 0.0
    edit_df["å¤‡æ³¨"] = ""

    st.markdown("**åœ¨ä¸‹è¡¨ä¸­å¡«å†™æ•°é‡ï¼ˆå¿…å¡«ï¼‰ï¼Œå•ä»·ä»…åœ¨ä¹°å…¥æ—¶å¡«å†™ï¼›å¯æ·»åŠ æ–°è¡Œå½•å…¥æ–°ç‰©å“**")
    edited = st.data_editor(
        edit_df,
        use_container_width=True,
        num_rows="dynamic",
        column_config={
            "æ•°é‡": st.column_config.NumberColumn(step=0.1, min_value=0.0),
            "å•ä»·": st.column_config.NumberColumn(step=0.01, min_value=0.0) if sel_status == "ä¹°å…¥" else None,
        },
        key="bulk_editor",
    )

    if st.button("âœ… æ‰¹é‡ä¿å­˜åˆ°ã€è´­å…¥/å‰©ä½™ã€"):
        rows = edited.copy()
        rows["æ•°é‡"] = pd.to_numeric(rows["æ•°é‡"], errors="coerce")
        rows = rows[(rows["æ•°é‡"].fillna(0) > 0) & (rows["ç‰©å“å"].astype(str).str.strip() != "")]
        if rows.empty:
            st.warning("è¯·è‡³å°‘å¡«å†™ä¸€ä¸ªç‰©å“çš„â€˜ç‰©å“åâ€™å’Œâ€˜æ•°é‡â€™")
            st.stop()

        ok, fail = 0, 0
        for _, r in rows.iterrows():
            qty   = float(r["æ•°é‡"])
            unit  = str(r.get("å•ä½", "") or "").strip()
            price = None
            total = None
            if sel_status == "ä¹°å…¥" and "å•ä»·" in r and pd.notna(r["å•ä»·"]):
                price = float(r["å•ä»·"])
                total = qty * price

            record = {
                "æ—¥æœŸ (Date)": pd.to_datetime(sel_date).strftime("%Y-%m-%d"),
                "é£Ÿæåç§° (Item Name)": str(r["ç‰©å“å"]).strip(),
                "åˆ†ç±» (Category)": sel_type,
                "æ•°é‡ (Qty)": qty,
                "å•ä½ (Unit)": unit,
                "å•ä»· (Unit Price)": price if sel_status == "ä¹°å…¥" else "",
                "æ€»ä»· (Total Cost)": total if sel_status == "ä¹°å…¥" else "",
                "çŠ¶æ€ (Status)": sel_status,
                "å¤‡æ³¨ (Notes)": str(r.get("å¤‡æ³¨", "")).strip(),
            }
            try:
                append_record(record)
                ok += 1
            except Exception as e:
                fail += 1
                st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")

        if ok and not fail:
            st.success(f"å·²æˆåŠŸå†™å…¥ {ok} æ¡è®°å½•ï¼")
        elif ok and fail:
            st.warning(f"éƒ¨åˆ†æˆåŠŸï¼š{ok} æ¡æˆåŠŸï¼Œ{fail} æ¡å¤±è´¥ã€‚")
        else:
            st.error("ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¡¨æ ¼æƒé™ä¸ Secrets é…ç½®ã€‚")

# ================== åº“å­˜ç»Ÿè®¡ ==================
with tabs[1]:
    st.subheader("åº“å­˜ç»Ÿè®¡ï¼ˆæœ€è¿‘ 14 å¤©ç”¨é‡ä¼°ç®—ï¼‰")

    colR1, _ = st.columns([1, 3])
    if colR1.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è¯»å– Google Sheet"):
        try: bust_cache()
        except: pass
        st.rerun()

    # è¯»æ˜ç»†å¹¶ç»Ÿä¸€åˆ—å
    try:
        df = read_records_fn()
        df = normalize_columns(df)
    except Exception as e:
        st.error(f"è¯»å–è¡¨æ ¼å¤±è´¥ï¼š{e}")
        st.stop()

    # å…œåº•åˆ†ç±»
    if "åˆ†ç±» (Category)" not in df.columns:
        df["åˆ†ç±» (Category)"] = DEFAULT_CAT
    else:
        df["åˆ†ç±» (Category)"] = df["åˆ†ç±» (Category)"].apply(normalize_cat)

    # æ€»ä½“ç»Ÿè®¡
    stats_all = compute_stats(df)

    # æ¯ä¸ª item çš„â€œæœ€è¿‘åˆ†ç±»â€ï¼ˆç”¨äºç­›é€‰ï¼‰
    if not df.empty and "é£Ÿæåç§° (Item Name)" in df.columns:
        latest_cat = (
            safe_sort(df, "æ—¥æœŸ (Date)")
            .groupby("é£Ÿæåç§° (Item Name)")["åˆ†ç±» (Category)"]
            .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else DEFAULT_CAT)
        )
        stats_all = stats_all.merge(latest_cat.rename("ç±»å‹"),
                                    left_on="é£Ÿæåç§° (Item Name)", right_index=True, how="left")
    else:
        stats_all["ç±»å‹"] = DEFAULT_CAT
    stats_all["ç±»å‹"] = stats_all["ç±»å‹"].apply(normalize_cat)

    # æ§ä»¶
    ctl1, ctl2, ctl3 = st.columns([1.2, 1, 1])
    sel_type = ctl1.selectbox("é€‰æ‹©ç±»åˆ«", ["å…¨éƒ¨"] + ALLOWED_CATS, index=0)
    warn_days   = ctl2.number_input("å…³æ³¨é˜ˆå€¼ï¼ˆå¤©ï¼‰", min_value=1, max_value=60, value=7, step=1)
    urgent_days = ctl3.number_input("ç´§æ€¥é˜ˆå€¼ï¼ˆå¤©ï¼‰", min_value=1, max_value=60, value=3, step=1)

    stats = stats_all.copy()
    if sel_type != "å…¨éƒ¨":
        stats = stats[stats["ç±»å‹"].eq(sel_type)]

    # é¢„è­¦
    def badge(days):
        x = pd.to_numeric(days, errors="coerce")
        if pd.isna(x): return ""
        if x <= urgent_days: return "ğŸš¨ ç«‹å³ä¸‹å•"
        if x <= warn_days:   return "ğŸŸ  å…³æ³¨"
        return "ğŸŸ¢ æ­£å¸¸"
    stats["åº“å­˜é¢„è­¦"] = stats["é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"].apply(badge)

    # KPI
    c1, c2, c3, c4 = st.columns(4)
    total_items = int(stats["é£Ÿæåç§° (Item Name)"].nunique()) if not stats.empty and "é£Ÿæåç§° (Item Name)" in stats.columns else 0
    total_spend = df.loc[df.get("çŠ¶æ€ (Status)") == "ä¹°å…¥", "æ€»ä»· (Total Cost)"].sum(min_count=1) if "æ€»ä»· (Total Cost)" in df.columns else 0
    low_days = pd.to_numeric(stats.get("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"), errors="coerce") if "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°" in stats.columns else pd.Series(dtype=float)
    need_buy = int((low_days <= warn_days).sum()) if not stats.empty else 0
    recent_usage_count = int((pd.to_numeric(stats.get("å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡"), errors="coerce") > 0).sum()) if not stats.empty else 0

    c1.metric(f"{sel_type} â€” è®°å½•é£Ÿææ•°" if sel_type!="å…¨éƒ¨" else "è®°å½•é£Ÿææ•°", value=total_items)
    c2.metric("ç´¯è®¡æ”¯å‡º", value=f"{(total_spend or 0):.2f}")
    c3.metric(f"â‰¤{warn_days}å¤©å³å°†è€—å°½", value=need_buy)
    c4.metric("æœ€è¿‘14å¤©å¯ä¼°ä½¿ç”¨è®°å½•æ•°", value=recent_usage_count)

    # ç»“æœè¡¨
    display_cols = [
        "é£Ÿæåç§° (Item Name)", "å½“å‰åº“å­˜", "å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡",
        "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "è®¡ç®—ä¸‹æ¬¡é‡‡è´­é‡",
        "æœ€è¿‘ç»Ÿè®¡å‰©ä½™æ—¥æœŸ", "æœ€è¿‘é‡‡è´­æ—¥æœŸ",
        "æœ€è¿‘é‡‡è´­æ•°é‡", "æœ€è¿‘é‡‡è´­å•ä»·",
        "å¹³å‡é‡‡è´­é—´éš”(å¤©)", "ç´¯è®¡æ”¯å‡º", "åº“å­˜é¢„è­¦"
    ]
    show = stats[[c for c in display_cols if c in stats.columns]].copy()

    severity = {"ğŸš¨ ç«‹å³ä¸‹å•": 0, "ğŸŸ  å…³æ³¨": 1, "ğŸŸ¢ æ­£å¸¸": 2, "": 3}
    if "åº“å­˜é¢„è­¦" in show.columns:
        show["__sev__"] = show["åº“å­˜é¢„è­¦"].map(severity).fillna(3)
        if "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°" in show.columns:
            show = show.sort_values(["__sev__", "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"], ascending=[True, True])
        show = show.drop(columns="__sev__", errors="ignore")

    if show.empty:
        st.info("è¯¥ç±»åˆ«ä¸‹æš‚æ— ç»Ÿè®¡ç»“æœï¼ˆå¯èƒ½æ˜¯åˆ†ç±»åˆ—ä¸ºç©ºæˆ–æœªè¢«è¯†åˆ«ï¼‰ã€‚è¯·æ£€æŸ¥ã€è´­å…¥/å‰©ä½™ã€è¡¨ä¸­çš„ã€åˆ†ç±» (Category)ã€‘æ˜¯å¦å¡«å†™æ­£ç¡®ã€‚")
    st.dataframe(show, use_container_width=True)

    # å¯¼å‡º
    csv = show.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ å¯¼å‡ºç»Ÿè®¡ç»“æœï¼ˆCSVï¼‰", data=csv,
                       file_name=f"inventory_stats_{sel_type}.csv", mime="text/csv")

    # ============ ä¸‹é’»ï¼šç‰©å“è¯¦æƒ… ============
    st.markdown("### ğŸ” ç‰©å“è¯¦æƒ…")
    detail_items = ["ï¼ˆä¸é€‰ï¼‰"] + list(show["é£Ÿæåç§° (Item Name)"].dropna().unique()) if "é£Ÿæåç§° (Item Name)" in show.columns else ["ï¼ˆä¸é€‰ï¼‰"]
    picked = st.selectbox("é€‰æ‹©ä¸€ä¸ªç‰©å“æŸ¥çœ‹è¯¦æƒ…", detail_items, index=0)

    if picked and picked != "ï¼ˆä¸é€‰ï¼‰":
        item_df = normalize_columns(df[df["é£Ÿæåç§° (Item Name)"] == picked].copy())
        item_df = safe_sort(item_df, "æ—¥æœŸ (Date)")

        rem = item_df[item_df.get("çŠ¶æ€ (Status)") == "å‰©ä½™"].copy()
        latest_rem = rem.iloc[-1] if len(rem) else None
        cur_stock = float(latest_rem["æ•°é‡ (Qty)"]) if latest_rem is not None else np.nan

        buy = item_df[item_df.get("çŠ¶æ€ (Status)") == "ä¹°å…¥"].copy()
        last_buy = buy.iloc[-1] if len(buy) else None
        last_buy_date = (last_buy["æ—¥æœŸ (Date)"].date().isoformat()
                         if last_buy is not None and pd.notna(last_buy["æ—¥æœŸ (Date)"]) else "â€”")
        last_buy_qty  = float(last_buy["æ•°é‡ (Qty)"]) if last_buy is not None else np.nan
        last_buy_price = float(last_buy["å•ä»· (Unit Price)"]) if (last_buy is not None and "å•ä»· (Unit Price)" in item_df.columns) else np.nan

        use14 = _recent_usage_14d_new(item_df)
        days_left = (cur_stock / (use14/14.0)) if (use14 and use14>0 and not np.isnan(cur_stock)) else np.nan
        stockout_date = (pd.Timestamp.today().normalize() + pd.Timedelta(days=float(days_left))).date().isoformat() \
                        if days_left == days_left else "â€”"

        if len(buy) >= 2:
            avg_interval = buy["æ—¥æœŸ (Date)"].diff().dt.days.dropna().mean()
        else:
            avg_interval = np.nan

        k1, k2, k3, k4, k5, k6 = st.columns(6)
        k1.metric("å½“å‰åº“å­˜", f"{0 if np.isnan(cur_stock) else cur_stock}")
        k2.metric("æœ€è¿‘14å¤©ç”¨é‡", f"{0 if not use14 else round(use14,2)}")
        k3.metric("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "â€”" if np.isnan(days_left) else f"{days_left:.2f}")
        k4.metric("é¢„è®¡ç¼ºè´§æ—¥æœŸ", stockout_date)
        k5.metric("æœ€è¿‘é‡‡è´­æ—¥æœŸ", last_buy_date)
        k6.metric("å¹³å‡é‡‡è´­é—´éš”(å¤©)", "â€”" if np.isnan(avg_interval) else f"{avg_interval:.1f}")

        # åº“å­˜è½¨è¿¹ï¼ˆè¿‘60å¤©ï¼‰
        lookback = pd.Timestamp.today().normalize() - pd.Timedelta(days=60)
        rem60 = rem[rem["æ—¥æœŸ (Date)"] >= lookback].copy()
        if not rem60.empty:
            rem60["dt"] = pd.to_datetime(rem60["æ—¥æœŸ (Date)"])
            chart_stock = alt.Chart(rem60).mark_line(point=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q", title="å‰©ä½™æ•°é‡")
            ).properties(title=f"{picked} â€” å‰©ä½™æ•°é‡ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_stock, use_container_width=True)

        # äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰
        ev = item_df[item_df["æ—¥æœŸ (Date)"] >= lookback][["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)"]].copy()
        if not ev.empty:
            ev["dt"] = pd.to_datetime(ev["æ—¥æœŸ (Date)"])
            chart_ev = alt.Chart(ev).mark_point(filled=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q"),
                shape="çŠ¶æ€ (Status):N",
                tooltip=["çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ—¥æœŸ (Date)"]
            ).properties(title=f"{picked} â€” äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_ev, use_container_width=True)

        # æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰
        st.markdown("#### æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰")
        cols = ["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ€»ä»· (Total Cost)","åˆ†ç±» (Category)","å¤‡æ³¨ (Notes)"]
        cols = [c for c in cols if c in item_df.columns]
        st.dataframe(safe_sort(item_df[cols], "æ—¥æœŸ (Date)").iloc[::-1].head(10), use_container_width=True)
