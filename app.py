# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

# ================= Secrets/ENV =================
if "service_account" in st.secrets:
    with open("service_account.json", "w") as f:
        json.dump(dict(st.secrets["service_account"]), f)

sheet_url = st.secrets.get("INVENTORY_SHEET_URL", None) or os.getenv("INVENTORY_SHEET_URL", None)
if sheet_url:
    os.environ["INVENTORY_SHEET_URL"] = sheet_url

# ================ Backend ======================
# append_record: å†™å› â€œè´­å…¥/å‰©ä½™â€
from gsheet import append_record

# è¯»â€œè´­å…¥/å‰©ä½™â€å’Œï¼ˆè‹¥æœ‰ï¼‰ä¸»æ•°æ®
try:
    from gsheet import read_records_cached as read_records_fn, read_catalog_cached as read_catalog_fn, bust_cache
except Exception:
    from gsheet import read_records as read_records_fn, read_catalog as read_catalog_fn
    def bust_cache(): pass

# computeï¼šå«â€œæœ€è¿‘14å¤©ç”¨é‡â€çš„ç¨³å¥ç®—æ³•
# ä½ è‡ªå·±çš„ compute.py é‡Œå¦‚æœæœ‰ compute_stats ä¸ _recent_usage_14d_robustï¼Œè¿™é‡Œä¼˜å…ˆç”¨ï¼›
# å¦åˆ™ fallback åˆ° _recent_usage_14d_newã€‚
try:
    from compute import compute_stats, _recent_usage_14d_robust as _recent_usage_14d_new
except Exception:
    from compute import compute_stats, _recent_usage_14d_new

# å…è®¸çš„å››ä¸ªç±»åˆ«ï¼ˆç¡¬ç¼–ç ï¼‰
ALLOWED_CATS = ["é£Ÿç‰©ç±»", "æ¸…æ´ç±»", "æ¶ˆè€—å“", "é¥®å“ç±»"]
DEFAULT_CAT = "é£Ÿç‰©ç±»"   # è‹¥åˆ†ç±»ç¼ºå¤±/ä¸è¯†åˆ«ï¼Œå½’ä¸ºæ­¤ç±»ï¼ˆå¯æ”¹ï¼‰

# ================ APP UI =======================
st.set_page_config(page_title="åº“å­˜ç®¡ç† Dashboard", layout="wide")
st.title("ğŸ± åº“å­˜ç®¡ç† Dashboard")
st.caption("å½•å…¥â€˜ä¹°å…¥/å‰©ä½™â€™ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°è¡¨æ ¼ï¼Œå¹¶å®æ—¶ç”Ÿæˆâ€˜åº“å­˜ç»Ÿè®¡â€™åˆ†æ")

tabs = st.tabs(["â• å½•å…¥è®°å½•", "ğŸ“Š åº“å­˜ç»Ÿè®¡"])

# ä¸€ä¸ªå°å·¥å…·ï¼šåˆ†ç±»æ ‡å‡†åŒ–ï¼ˆç©ºå€¼/å¼‚å¸¸ â†’ DEFAULT_CATï¼‰
def _normalize_cat(x: str) -> str:
    if x is None:
        return DEFAULT_CAT
    s = str(x).strip()
    if s == "" or s.lower() in ("nan", "none"):
        return DEFAULT_CAT
    return s if s in ALLOWED_CATS else DEFAULT_CAT

# ================== å½•å…¥è®°å½• ==================
with tabs[0]:
    st.subheader("å½•å…¥æ–°è®°å½•")

    # å…ˆå°è¯•è¯»å–â€œè´­å…¥/å‰©ä½™â€ï¼Œç”¨äºåœ¨æ²¡æœ‰ä¸»æ•°æ®æ—¶æ¨æ–­â€˜å·²æœ‰ç‰©å“+å•ä½â€™
    try:
        df_all = read_records_fn()
    except Exception as e:
        df_all = pd.DataFrame()
        st.info("æš‚æ—¶è¯»å–ä¸åˆ°ã€è´­å…¥/å‰©ä½™ã€ï¼Œä»…å¯æ‰‹åŠ¨æ–°å¢è¡Œã€‚")

    # ä¸»æ•°æ®ï¼ˆä»…ç”¨äºä¸‹æ‹‰å±•ç¤ºâ€œç‰©å“å/å•ä½â€ï¼›æ²¡æœ‰ä¹Ÿä¸å½±å“å½•å…¥ï¼‰
    try:
        catalog = read_catalog_fn()
    except Exception:
        catalog = pd.DataFrame()

    c1, c2, c3 = st.columns(3)
    sel_date   = c1.date_input("æ—¥æœŸ (Date)", pd.Timestamp.today())
    sel_type   = c2.selectbox("ç±»å‹ï¼ˆå¤§ç±»ï¼‰", ALLOWED_CATS, index=0)
    sel_status = c3.selectbox("çŠ¶æ€ (Status)", ["ä¹°å…¥", "å‰©ä½™"])

    # ======== æ„é€ å¯ç¼–è¾‘è¡¨ ========
    # ä¼˜å…ˆç”¨ä¸»æ•°æ®ï¼ˆè¦æ±‚è‡³å°‘å« ç‰©å“å/å•ä½/ç±»å‹ï¼‰ï¼›å¦åˆ™ç”¨å†å²è®°å½•æ¨æ–­
    if not catalog.empty and {"ç‰©å“å","å•ä½","ç±»å‹"}.issubset(catalog.columns):
        base = catalog[catalog["ç±»å‹"] == sel_type][["ç‰©å“å","å•ä½"]].drop_duplicates().reset_index(drop=True)
    else:
        # ä»å†å²è®°å½•é‡Œï¼Œå–è¯¥å¤§ç±»ä¸‹å„ç‰©å“â€œæœ€è¿‘ä¸€æ¡è®°å½•â€çš„å•ä½
        if not df_all.empty:
            df_all = df_all.copy()
            if "åˆ†ç±» (Category)" not in df_all.columns:
                df_all["åˆ†ç±» (Category)"] = DEFAULT_CAT
            df_all["åˆ†ç±» (Category)"] = df_all["åˆ†ç±» (Category)"].apply(_normalize_cat)

            latest_unit = (df_all[df_all["åˆ†ç±» (Category)"] == sel_type]
                           .sort_values("æ—¥æœŸ (Date)")
                           .groupby("é£Ÿæåç§° (Item Name)")["å•ä½ (Unit)"]
                           .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else "")
                           .reset_index()
                           .rename(columns={"é£Ÿæåç§° (Item Name)":"ç‰©å“å","å•ä½ (Unit)":"å•ä½"}))
            base = latest_unit
        else:
            base = pd.DataFrame(columns=["ç‰©å“å","å•ä½"])

    # æ„é€ å¯ç¼–è¾‘ DataFrameï¼Œå¹¶å…è®¸â€œæ‰‹åŠ¨æ–°å¢è¡Œâ€
    edit_df = base.copy()
    if "ç‰©å“å" not in edit_df.columns: edit_df["ç‰©å“å"] = ""
    if "å•ä½" not in edit_df.columns:   edit_df["å•ä½"] = ""
    edit_df["æ•°é‡"] = 0.0
    if sel_status == "ä¹°å…¥":
        edit_df["å•ä»·"] = 0.0
    edit_df["å¤‡æ³¨"] = ""

    st.markdown("**åœ¨ä¸‹è¡¨ä¸­å¡«å†™æ•°é‡ï¼ˆå¿…å¡«ï¼‰ï¼Œå•ä»·ä»…åœ¨ä¹°å…¥æ—¶å¡«å†™ï¼›å¯æ·»åŠ æ–°è¡Œå½•å…¥æ–°ç‰©å“**")
    edited = st.data_editor(
        edit_df,
        use_container_width=True,
        num_rows="dynamic",
        column_config={
            # å½“æ¥è‡ªä¸»æ•°æ®/å†å²è®°å½•æ—¶ï¼Œç‰©å“å/å•ä½å¯ç¼–è¾‘ï¼ˆå…è®¸æ–°å¢/ä¿®æ­£ï¼‰
            "æ•°é‡": st.column_config.NumberColumn(step=0.1, min_value=0.0),
            "å•ä»·": st.column_config.NumberColumn(step=0.01, min_value=0.0) if sel_status == "ä¹°å…¥" else None,
        },
        key="bulk_editor",
    )

    if st.button("âœ… æ‰¹é‡ä¿å­˜åˆ°ã€è´­å…¥/å‰©ä½™ã€"):
        rows = edited.copy()
        # ä»…ä¿ç•™æ•°é‡>0 ä¸” ç‰©å“åéç©º çš„è¡Œ
        rows["æ•°é‡"] = pd.to_numeric(rows["æ•°é‡"], errors="coerce")
        rows = rows[(rows["æ•°é‡"].fillna(0) > 0) & (rows["ç‰©å“å"].astype(str).str.strip() != "")]
        if rows.empty:
            st.warning("è¯·è‡³å°‘å¡«å†™ä¸€ä¸ªç‰©å“çš„â€˜ç‰©å“åâ€™å’Œâ€˜æ•°é‡â€™")
            st.stop()

        ok, fail = 0, 0
        for _, r in rows.iterrows():
            qty   = float(r["æ•°é‡"])
            unit  = str(r.get("å•ä½", "") or "").strip()
            price = None
            total = None
            if sel_status == "ä¹°å…¥" and "å•ä»·" in r and pd.notna(r["å•ä»·"]):
                price = float(r["å•ä»·"])
                total = qty * price

            record = {
                "æ—¥æœŸ (Date)": pd.to_datetime(sel_date).strftime("%Y-%m-%d"),
                "é£Ÿæåç§° (Item Name)": str(r["ç‰©å“å"]).strip(),
                "åˆ†ç±» (Category)": sel_type,   # ä½¿ç”¨æ‰€é€‰å¤§ç±»
                "æ•°é‡ (Qty)": qty,
                "å•ä½ (Unit)": unit,
                "å•ä»· (Unit Price)": price if sel_status == "ä¹°å…¥" else "",
                "æ€»ä»· (Total Cost)": total if sel_status == "ä¹°å…¥" else "",
                "çŠ¶æ€ (Status)": sel_status,
                "å¤‡æ³¨ (Notes)": str(r.get("å¤‡æ³¨", "")).strip(),
            }
            try:
                append_record(record)
                ok += 1
            except Exception as e:
                fail += 1
                st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")

        if ok and not fail:
            st.success(f"å·²æˆåŠŸå†™å…¥ {ok} æ¡è®°å½•ï¼")
        elif ok and fail:
            st.warning(f"éƒ¨åˆ†æˆåŠŸï¼š{ok} æ¡æˆåŠŸï¼Œ{fail} æ¡å¤±è´¥ã€‚")
        else:
            st.error("ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¡¨æ ¼æƒé™ä¸ Secrets é…ç½®ã€‚")

# ================== åº“å­˜ç»Ÿè®¡ ==================
with tabs[1]:
    st.subheader("åº“å­˜ç»Ÿè®¡ï¼ˆæœ€è¿‘ 14 å¤©ç”¨é‡ä¼°ç®—ï¼‰")

    colR1, _ = st.columns([1, 3])
    if colR1.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è¯»å– Google Sheet"):
        try: bust_cache()
        except: pass
        st.rerun()

    # è¯»æ˜ç»†
    try:
        df = read_records_fn()
    except Exception as e:
        st.error(f"è¯»å–è¡¨æ ¼å¤±è´¥ï¼š{e}")
        st.stop()

    # ---------- å…³é”®ï¼šæ¸…æ´—/å…œåº•åˆ†ç±» ----------
    if "åˆ†ç±» (Category)" not in df.columns:
        df["åˆ†ç±» (Category)"] = ""
    df["åˆ†ç±» (Category)"] = df["åˆ†ç±» (Category)"].astype(str).str.strip().apply(_normalize_cat)

    # è®¡ç®—æ•´ä½“ç»Ÿè®¡ï¼ˆä¸ä¾èµ–ç±»åˆ«ï¼‰
    stats_all = compute_stats(df)

    # æ¯ä¸ª item çš„â€œæœ€è¿‘åˆ†ç±»â€ï¼ˆç”¨äºç­›é€‰ï¼‰
    latest_cat = (
        df.sort_values("æ—¥æœŸ (Date)")
          .groupby("é£Ÿæåç§° (Item Name)")["åˆ†ç±» (Category)"]
          .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else DEFAULT_CAT)
    )
    stats_all = stats_all.merge(latest_cat.rename("ç±»å‹"),
                                left_on="é£Ÿæåç§° (Item Name)", right_index=True, how="left")
    stats_all["ç±»å‹"] = stats_all["ç±»å‹"].apply(_normalize_cat)

    # é€‰æ‹©ç±»åˆ« + é˜ˆå€¼
    ctl1, ctl2, ctl3 = st.columns([1.2, 1, 1])
    sel_type = ctl1.selectbox("é€‰æ‹©ç±»åˆ«", ["å…¨éƒ¨"] + ALLOWED_CATS, index=0)
    warn_days   = ctl2.number_input("å…³æ³¨é˜ˆå€¼ï¼ˆå¤©ï¼‰", min_value=1, max_value=60, value=7, step=1)
    urgent_days = ctl3.number_input("ç´§æ€¥é˜ˆå€¼ï¼ˆå¤©ï¼‰", min_value=1, max_value=60, value=3, step=1)

    stats = stats_all.copy()
    if sel_type != "å…¨éƒ¨":
        stats = stats[stats["ç±»å‹"].eq(sel_type)]

    # é¢„è­¦æ ‡ç­¾
    def badge(days):
        x = pd.to_numeric(days, errors="coerce")
        if pd.isna(x): return ""
        if x <= urgent_days: return "ğŸš¨ ç«‹å³ä¸‹å•"
        if x <= warn_days:   return "ğŸŸ  å…³æ³¨"
        return "ğŸŸ¢ æ­£å¸¸"
    stats["åº“å­˜é¢„è­¦"] = stats["é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"].apply(badge)

    # é¡¶éƒ¨ KPI
    c1, c2, c3, c4 = st.columns(4)
    total_items = int(stats["é£Ÿæåç§° (Item Name)"].nunique()) if not stats.empty else 0
    total_spend = df.loc[df["çŠ¶æ€ (Status)"] == "ä¹°å…¥", "æ€»ä»· (Total Cost)"].sum(min_count=1)
    low_days = pd.to_numeric(stats["é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"], errors="coerce")
    need_buy = int((low_days <= warn_days).sum()) if not stats.empty else 0
    recent_usage_count = int((pd.to_numeric(stats["å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡"], errors="coerce") > 0).sum()) if not stats.empty else 0

    c1.metric(f"{sel_type} â€” è®°å½•é£Ÿææ•°" if sel_type!="å…¨éƒ¨" else "è®°å½•é£Ÿææ•°", value=total_items)
    c2.metric("ç´¯è®¡æ”¯å‡º", value=f"{(total_spend or 0):.2f}")
    c3.metric(f"â‰¤{warn_days}å¤©å³å°†è€—å°½", value=need_buy)
    c4.metric("æœ€è¿‘14å¤©å¯ä¼°ä½¿ç”¨è®°å½•æ•°", value=recent_usage_count)

    # ç»Ÿè®¡ç»“æœè¡¨ï¼ˆåªå±•ç¤ºè®¡ç®—å­—æ®µï¼‰
    display_cols = [
        "é£Ÿæåç§° (Item Name)", "å½“å‰åº“å­˜", "å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡",
        "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "è®¡ç®—ä¸‹æ¬¡é‡‡è´­é‡",
        "æœ€è¿‘ç»Ÿè®¡å‰©ä½™æ—¥æœŸ", "æœ€è¿‘é‡‡è´­æ—¥æœŸ",
        "æœ€è¿‘é‡‡è´­æ•°é‡", "æœ€è¿‘é‡‡è´­å•ä»·",
        "å¹³å‡é‡‡è´­é—´éš”(å¤©)", "ç´¯è®¡æ”¯å‡º", "åº“å­˜é¢„è­¦"
    ]
    show = stats[[c for c in display_cols if c in stats.columns]].copy()

    # æŒ‰é¢„è­¦ä¸¥é‡ç¨‹åº¦æ’åºï¼šğŸš¨ > ğŸŸ  > ğŸŸ¢ > ç©º
    severity = {"ğŸš¨ ç«‹å³ä¸‹å•": 0, "ğŸŸ  å…³æ³¨": 1, "ğŸŸ¢ æ­£å¸¸": 2, "": 3}
    show["__sev__"] = show["åº“å­˜é¢„è­¦"].map(severity).fillna(3)
    show = show.sort_values(["__sev__", "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"], ascending=[True, True]).drop(columns="__sev__")

    if show.empty:
        st.info("è¯¥ç±»åˆ«ä¸‹æš‚æ— ç»Ÿè®¡ç»“æœï¼ˆå¯èƒ½æ˜¯åˆ†ç±»åˆ—ä¸ºç©ºæˆ–æœªè¢«è¯†åˆ«ï¼‰ã€‚è¯·æ£€æŸ¥ã€è´­å…¥/å‰©ä½™ã€è¡¨ä¸­çš„ã€åˆ†ç±» (Category)ã€‘æ˜¯å¦å¡«å†™æ­£ç¡®ã€‚")
    st.dataframe(show, use_container_width=True)

    # å¯¼å‡º
    csv = show.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ å¯¼å‡ºç»Ÿè®¡ç»“æœï¼ˆCSVï¼‰", data=csv,
                       file_name=f"inventory_stats_{sel_type}.csv", mime="text/csv")

    # ============ ä¸‹é’»ï¼šç‰©å“è¯¦æƒ… ============
    st.markdown("### ğŸ” ç‰©å“è¯¦æƒ…")
    detail_items = ["ï¼ˆä¸é€‰ï¼‰"] + list(show["é£Ÿæåç§° (Item Name)"].dropna().unique())
    picked = st.selectbox("é€‰æ‹©ä¸€ä¸ªç‰©å“æŸ¥çœ‹è¯¦æƒ…", detail_items, index=0)

    if picked and picked != "ï¼ˆä¸é€‰ï¼‰":
        item_df = (
            df[df["é£Ÿæåç§° (Item Name)"] == picked]
            .copy()
            .sort_values("æ—¥æœŸ (Date)")
        )

        rem = item_df[item_df["çŠ¶æ€ (Status)"] == "å‰©ä½™"].copy()
        latest_rem = rem.iloc[-1] if len(rem) else None
        cur_stock = float(latest_rem["æ•°é‡ (Qty)"]) if latest_rem is not None else np.nan

        buy = item_df[item_df["çŠ¶æ€ (Status)"] == "ä¹°å…¥"].copy()
        last_buy = buy.iloc[-1] if len(buy) else None
        last_buy_date = (last_buy["æ—¥æœŸ (Date)"].date().isoformat()
                         if last_buy is not None and pd.notna(last_buy["æ—¥æœŸ (Date)"]) else "â€”")
        last_buy_qty  = float(last_buy["æ•°é‡ (Qty)"]) if last_buy is not None else np.nan
        last_buy_price = float(last_buy["å•ä»· (Unit Price)"]) if last_buy is not None else np.nan

        use14 = _recent_usage_14d_new(item_df)
        days_left = (cur_stock / (use14/14.0)) if (use14 and use14>0 and not np.isnan(cur_stock)) else np.nan
        stockout_date = (pd.Timestamp.today().normalize() + pd.Timedelta(days=float(days_left))).date().isoformat() \
                        if days_left == days_left else "â€”"

        if len(buy) >= 2:
            avg_interval = (buy["æ—¥æœŸ (Date)"].diff().dt.days.dropna().mean())
        else:
            avg_interval = np.nan

        end = pd.Timestamp.today().normalize()
        start = end - pd.Timedelta(days=14)
        recent_buys = buy[(buy["æ—¥æœŸ (Date)"] >= start) & (buy["æ—¥æœŸ (Date)"] <= end)]
        spend14 = recent_buys["æ€»ä»· (Total Cost)"].sum(min_count=1)
        spend14_perday = spend14 / 14.0 if spend14 == spend14 else np.nan

        k1, k2, k3, k4, k5, k6 = st.columns(6)
        k1.metric("å½“å‰åº“å­˜", f"{0 if np.isnan(cur_stock) else cur_stock}")
        k2.metric("æœ€è¿‘14å¤©ç”¨é‡", f"{0 if not use14 else round(use14,2)}")
        k3.metric("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "â€”" if np.isnan(days_left) else f"{days_left:.2f}")
        k4.metric("é¢„è®¡ç¼ºè´§æ—¥æœŸ", stockout_date)
        k5.metric("æœ€è¿‘é‡‡è´­æ—¥æœŸ", last_buy_date)
        k6.metric("å¹³å‡é‡‡è´­é—´éš”(å¤©)", "â€”" if np.isnan(avg_interval) else f"{avg_interval:.1f}")

        # åº“å­˜è½¨è¿¹ï¼ˆè¿‘60å¤©ï¼‰
        lookback = pd.Timestamp.today().normalize() - pd.Timedelta(days=60)
        rem60 = rem[rem["æ—¥æœŸ (Date)"] >= lookback].copy()
        if not rem60.empty:
            rem60["dt"] = pd.to_datetime(rem60["æ—¥æœŸ (Date)"])
            chart_stock = alt.Chart(rem60).mark_line(point=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q", title="å‰©ä½™æ•°é‡")
            ).properties(title=f"{picked} â€” å‰©ä½™æ•°é‡ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_stock, use_container_width=True)

        # äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰
        ev = item_df[item_df["æ—¥æœŸ (Date)"] >= lookback][["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)"]].copy()
        if not ev.empty:
            ev["dt"] = pd.to_datetime(ev["æ—¥æœŸ (Date)"])
            chart_ev = alt.Chart(ev).mark_point(filled=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q"),
                shape="çŠ¶æ€ (Status):N",
                tooltip=["çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ—¥æœŸ (Date)"]
            ).properties(title=f"{picked} â€” äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_ev, use_container_width=True)

        # æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰
        st.markdown("#### æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰")
        cols = ["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ€»ä»· (Total Cost)","åˆ†ç±» (Category)","å¤‡æ³¨ (Notes)"]
        st.dataframe(item_df[cols].sort_values("æ—¥æœŸ (Date)", ascending=False).head(10), use_container_width=True)
