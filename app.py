# -*- coding: utf-8 -*-
import os
import json
import re
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

# ================= Secrets/ENV =================
if "service_account" in st.secrets:
    with open("service_account.json", "w") as f:
        json.dump(dict(st.secrets["service_account"]), f)

sheet_url = st.secrets.get("INVENTORY_SHEET_URL", None) or os.getenv("INVENTORY_SHEET_URL", None)
if sheet_url:
    os.environ["INVENTORY_SHEET_URL"] = sheet_url

# ================ Backend ======================
from gsheet import append_record, append_records_bulk
try:
    from gsheet import read_records_cached as read_records_fn, read_catalog_cached as read_catalog_fn, bust_cache
except Exception:
    from gsheet import read_records as read_records_fn, read_catalog as read_catalog_fn
    def bust_cache(): pass

# è®¡ç®—é€»è¾‘ä¸å¼ºåŠ›åˆ—åè§„èŒƒåŒ–å‡åœ¨ compute.py
try:
    from compute import compute_stats, _recent_usage_14d_robust as _recent_usage_14d_new, normalize_columns as normalize_columns_compute
except Exception:
    from compute import compute_stats, _recent_usage_14d_new
    def normalize_columns_compute(df: pd.DataFrame) -> pd.DataFrame:
        return df

# å…è®¸çš„å››ä¸ªç±»åˆ«ï¼ˆç¡¬ç¼–ç ï¼‰
ALLOWED_CATS = ["é£Ÿç‰©ç±»", "æ¸…æ´ç±»", "æ¶ˆè€—å“", "é¥®å“ç±»"]
DEFAULT_CAT = "é£Ÿç‰©ç±»"

# ============== ä»…ç”¨äºå½•å…¥é¡µçš„è½»é‡å·¥å…· ==============
def safe_sort(df: pd.DataFrame, by: str, ascending=True):
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def normalize_cat(x: str) -> str:
    if x is None:
        return DEFAULT_CAT
    s = str(x).strip()
    if s == "" or s.lower() in ("nan","none"):
        return DEFAULT_CAT
    return s if s in ALLOWED_CATS else DEFAULT_CAT

# ================ APP UI =======================
st.set_page_config(page_title="Gangnam åº“å­˜ç®¡ç†", layout="wide")
# é¡¶éƒ¨å¸ƒå±€ï¼šå·¦è¾¹ logoï¼Œå³è¾¹æ ‡é¢˜
c1, c2 = st.columns([1, 6])   # å·¦å³åˆ—æ¯”ä¾‹

with c1:
    st.image("gangnam_logo.png", width=180)  # è°ƒå¤§å›¾ç‰‡å®½åº¦

with c2:
    st.markdown(
        """
        <div style="display:flex; flex-direction:column; justify-content:center; height:100%;">
            <h1 style="margin-bottom:0;">Gangnam åº“å­˜ç®¡ç†</h1>
            <p style="color:gray; font-size:16px; margin-top:4px;">
                å½•å…¥â€˜ä¹°å…¥/å‰©ä½™â€™ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°è¡¨æ ¼ï¼Œå¹¶å®æ—¶ç”Ÿæˆâ€˜åº“å­˜ç»Ÿè®¡â€™åˆ†æ
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )

tabs = st.tabs(["â• å½•å…¥è®°å½•", "ğŸ“Š åº“å­˜ç»Ÿè®¡"])

# ================== å½•å…¥è®°å½• ==================
with tabs[0]:
    st.subheader("å½•å…¥æ–°è®°å½•")

    # è¯»å–â€œè´­å…¥/å‰©ä½™â€ç”¨äºæ¨æ–­å·²æœ‰ç‰©å“ï¼ˆå½“æ²¡æœ‰ä¸»æ•°æ®æ—¶ï¼‰
    try:
        df_all = read_records_fn()
        df_all = normalize_columns_compute(df_all)  # ä½¿ç”¨ compute çš„å¼ºåŠ›æ¸…æ´—
    except Exception:
        df_all = pd.DataFrame()

    # ä¸»æ•°æ®å¯é€‰
    try:
        catalog = read_catalog_fn()
    except Exception:
        catalog = pd.DataFrame()

    c1, c2, c3 = st.columns(3)
    sel_date   = c1.date_input("æ—¥æœŸ (Date)", pd.Timestamp.today())
    sel_type   = c2.selectbox("ç±»å‹ï¼ˆå¤§ç±»ï¼‰", ALLOWED_CATS, index=0)
    sel_status = c3.selectbox("çŠ¶æ€ (Status)", ["ä¹°å…¥", "å‰©ä½™"])

    # æ„é€ å¯ç¼–è¾‘è¡¨ï¼šä¼˜å…ˆä¸»æ•°æ®ï¼Œå¦åˆ™å†å²è®°å½•ä¸­è¯¥ç±»çš„æœ€è¿‘å•ä½
    if not catalog.empty and {"ç‰©å“å","å•ä½","ç±»å‹"}.issubset(catalog.columns):
        base = catalog[catalog["ç±»å‹"] == sel_type][["ç‰©å“å","å•ä½"]].drop_duplicates().reset_index(drop=True)
    else:
        if not df_all.empty:
            tmp = df_all.copy()
            if "åˆ†ç±» (Category)" not in tmp.columns:
                tmp["åˆ†ç±» (Category)"] = DEFAULT_CAT
            tmp["åˆ†ç±» (Category)"] = tmp["åˆ†ç±» (Category)"].apply(normalize_cat)
            latest_unit = (
                safe_sort(tmp[tmp["åˆ†ç±» (Category)"] == sel_type], "æ—¥æœŸ (Date)")
                .groupby("é£Ÿæåç§° (Item Name)")["å•ä½ (Unit)"]
                .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else "")
                .reset_index()
                .rename(columns={"é£Ÿæåç§° (Item Name)":"ç‰©å“å","å•ä½ (Unit)":"å•ä½"})
            )
            base = latest_unit
        else:
            base = pd.DataFrame(columns=["ç‰©å“å","å•ä½"])

    edit_df = base.copy()
    for col in ["ç‰©å“å","å•ä½"]:
        if col not in edit_df.columns: edit_df[col] = ""
    edit_df["æ•°é‡"] = 0.0
    if sel_status == "ä¹°å…¥":
        edit_df["å•ä»·"] = 0.0
    edit_df["å¤‡æ³¨"] = ""

    st.markdown("**åœ¨ä¸‹è¡¨ä¸­å¡«å†™æ•°é‡ï¼ˆå¿…å¡«ï¼‰ï¼Œå•ä»·ä»…åœ¨ä¹°å…¥æ—¶å¡«å†™ï¼›å¯æ·»åŠ æ–°è¡Œå½•å…¥æ–°ç‰©å“**")
    edited = st.data_editor(
        edit_df,
        use_container_width=True,
        num_rows="dynamic",
        column_config={
            "æ•°é‡": st.column_config.NumberColumn(step=0.1, min_value=0.0),
            "å•ä»·": st.column_config.NumberColumn(step=0.01, min_value=0.0) if sel_status == "ä¹°å…¥" else None,
        },
        key="bulk_editor",
    )

    if st.button("âœ… æ‰¹é‡ä¿å­˜åˆ°ã€è´­å…¥/å‰©ä½™ã€"):
        rows = edited.copy()
        rows["æ•°é‡"] = pd.to_numeric(rows["æ•°é‡"], errors="coerce")
        rows = rows[(rows["æ•°é‡"].fillna(0) > 0) & (rows["ç‰©å“å"].astype(str).str.strip() != "")]
    if rows.empty:
        st.warning("è¯·è‡³å°‘å¡«å†™ä¸€ä¸ªç‰©å“çš„â€˜ç‰©å“åâ€™å’Œâ€˜æ•°é‡â€™")
        st.stop()

    # === ç»„è£… records åˆ—è¡¨ï¼ˆä¸€æ¬¡æ‰¹é‡å†™å…¥ï¼‰ ===
    records = []
    for _, r in rows.iterrows():
        qty   = float(r["æ•°é‡"])
        unit  = str(r.get("å•ä½", "") or "").strip()
        price = None
        total = None
        if sel_status == "ä¹°å…¥" and "å•ä»·" in r and pd.notna(r["å•ä»·"]):
            price = float(r["å•ä»·"])
            total = qty * price

        records.append({
            "æ—¥æœŸ (Date)": pd.to_datetime(sel_date).strftime("%Y-%m-%d"),
            "é£Ÿæåç§° (Item Name)": str(r["ç‰©å“å"]).strip(),
            "åˆ†ç±» (Category)": sel_type,
            "æ•°é‡ (Qty)": qty,
            "å•ä½ (Unit)": unit,
            "å•ä»· (Unit Price)": price if sel_status == "ä¹°å…¥" else "",
            "æ€»ä»· (Total Cost)": total if sel_status == "ä¹°å…¥" else "",
            "çŠ¶æ€ (Status)": sel_status,
            "å¤‡æ³¨ (Notes)": str(r.get("å¤‡æ³¨", "")).strip(),
        })

    try:
        # ä¸€æ¬¡è°ƒç”¨ï¼Œæ˜¾è‘—å‡å°‘å†™è¯·æ±‚æ¬¡æ•°
        from gsheet import append_records_bulk
        append_records_bulk(records)
        st.success(f"å·²æˆåŠŸå†™å…¥ {len(records)} æ¡è®°å½•ï¼")
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")

        if ok and not fail:
            st.success(f"å·²æˆåŠŸå†™å…¥ {ok} æ¡è®°å½•ï¼")
        elif ok and fail:
            st.warning(f"éƒ¨åˆ†æˆåŠŸï¼š{ok} æ¡æˆåŠŸï¼Œ{fail} æ¡å¤±è´¥ã€‚")
        else:
            st.error("ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¡¨æ ¼æƒé™ä¸ Secrets é…ç½®ã€‚")

# ================== åº“å­˜ç»Ÿè®¡ ==================
with tabs[1]:
    st.subheader("åº“å­˜ç»Ÿè®¡")

    colR1, _ = st.columns([1, 3])
    if colR1.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è¯»å– Google Sheet"):
        try: bust_cache()
        except: pass
        st.rerun()

    # è¯»æ˜ç»†å¹¶ç»Ÿä¸€åˆ—å â€”â€” ä½¿ç”¨ compute çš„è§„èŒƒåŒ–
    try:
        df = read_records_fn()
        df = normalize_columns_compute(df)
    except Exception as e:
        st.error(f"è¯»å–è¡¨æ ¼å¤±è´¥ï¼š{e}")
        st.stop()

    # è°ƒè¯•é¢æ¿
    with st.expander("ğŸ” è°ƒè¯•ï¼šæŸ¥çœ‹åŸå§‹æ•°æ®å¿«ç…§", expanded=False):
        st.write("shape:", df.shape)
        st.write("columns:", list(df.columns))
        for col in ["æ—¥æœŸ (Date)","é£Ÿæåç§° (Item Name)","åˆ†ç±» (Category)","çŠ¶æ€ (Status)"]:
            if col in df.columns:
                st.write(f"{col} éç©ºæ•°é‡:", int(df[col].notna().sum()))
            else:
                st.write(f"âš ï¸ æœªè¯†åˆ«åˆ—ï¼š{col}")
        if not df.empty:
            st.dataframe(df.head(10), use_container_width=True)

    # å…œåº•åˆ†ç±»
    if "åˆ†ç±» (Category)" not in df.columns:
        df["åˆ†ç±» (Category)"] = DEFAULT_CAT
    else:
        df["åˆ†ç±» (Category)"] = df["åˆ†ç±» (Category)"].apply(normalize_cat)

    # ç»Ÿè®¡
    stats_all = compute_stats(df)

    # â€œç±»å‹â€åˆ—ç”¨äºç­›é€‰
    if not df.empty and "é£Ÿæåç§° (Item Name)" in df.columns:
        latest_cat = (
            df.sort_values("æ—¥æœŸ (Date)")
            .groupby("é£Ÿæåç§° (Item Name)")["åˆ†ç±» (Category)"]
            .agg(lambda s: s.dropna().iloc[-1] if len(s.dropna()) else DEFAULT_CAT)
        )
        stats_all = stats_all.merge(latest_cat.rename("ç±»å‹"),
                                    left_on="é£Ÿæåç§° (Item Name)", right_index=True, how="left")
    else:
        stats_all["ç±»å‹"] = DEFAULT_CAT
    stats_all["ç±»å‹"] = stats_all["ç±»å‹"].apply(normalize_cat)

    # === ç­›é€‰æ¡ï¼ˆä½œç”¨äºä¸‹æ–¹ç»“æœè¡¨ï¼‰ ===
    st.markdown("#### ç­›é€‰")
    fc1, _ = st.columns([1, 3])
    sel_type_bar = fc1.selectbox("é€‰æ‹©åˆ†ç±»", ["å…¨éƒ¨"] + ALLOWED_CATS, index=0)
    if sel_type_bar == "å…¨éƒ¨":
        stats = stats_all.copy()
    else:
        stats = stats_all[stats_all["ç±»å‹"].eq(sel_type_bar)].copy()

    # é¢„è­¦ï¼šæ™®é€š<5ï¼›ç™¾åˆ†æ¯”/ç³–æµ†<20%
    def _is_percent_row(row: pd.Series) -> bool:
        name = str(row.get("é£Ÿæåç§° (Item Name)","") or "")
        unit = str(row.get("å•ä½ (Unit)","") or "").strip()
        last_rem = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
        if "ç³–æµ†" in name:
            return True
        if unit in ["%", "ï¼…", "ç™¾åˆ†æ¯”", "percent", "ratio"]:
            return True
        if pd.notna(last_rem) and 0.0 <= float(last_rem) <= 1.0:
            return True
        return False

    def badge_row(row: pd.Series) -> str:
        if _is_percent_row(row):
            val = pd.to_numeric(row.get("æœ€è¿‘å‰©ä½™æ•°é‡"), errors="coerce")
            if pd.notna(val) and float(val) < 0.2:
                return "ğŸš¨ ç«‹å³ä¸‹å•"
            return "ğŸŸ¢ æ­£å¸¸"
        else:
            val = pd.to_numeric(row.get("å½“å‰åº“å­˜"), errors="coerce")
            if pd.notna(val) and float(val) < 5:
                return "ğŸš¨ ç«‹å³ä¸‹å•"
            return "ğŸŸ¢ æ­£å¸¸"

    if not stats.empty:
        stats["åº“å­˜é¢„è­¦"] = stats.apply(badge_row, axis=1)
    else:
        stats["åº“å­˜é¢„è­¦"] = ""

    # ä»…ä¿ç•™ä¸€ä¸ª KPIï¼šè®°å½•é£Ÿææ•°ï¼ˆåˆ é™¤å…¶ä½™ä¸‰å—ï¼‰
    c1, = st.columns(1)
    total_items = int(stats["é£Ÿæåç§° (Item Name)"].nunique()) if not stats.empty and "é£Ÿæåç§° (Item Name)" in stats.columns else 0
    c1.metric("è®°å½•æ•°é‡", value=total_items)

    # ç»“æœè¡¨
    display_cols = [
        "é£Ÿæåç§° (Item Name)", "å½“å‰åº“å­˜", "å•ä½ (Unit)", "å¹³å‡æœ€è¿‘ä¸¤å‘¨ä½¿ç”¨é‡",
        "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°",
        "æœ€è¿‘ç»Ÿè®¡å‰©ä½™æ—¥æœŸ", "æœ€è¿‘é‡‡è´­æ—¥æœŸ",
        "æœ€è¿‘é‡‡è´­æ•°é‡", "æœ€è¿‘é‡‡è´­å•ä»·",
        "å¹³å‡é‡‡è´­é—´éš”(å¤©)", "ç´¯è®¡æ”¯å‡º", "åº“å­˜é¢„è­¦"
    ]
    show = stats[[c for c in display_cols if c in stats.columns]].copy()

    # æ’åºï¼šæŒ‰é¢„è­¦ä¸¥é‡&è¿˜èƒ½ç”¨å¤©æ•°
    severity = {"ğŸš¨ ç«‹å³ä¸‹å•": 0, "ğŸŸ¢ æ­£å¸¸": 2, "": 3}
    if "åº“å­˜é¢„è­¦" in show.columns:
        show["__sev__"] = show["åº“å­˜é¢„è­¦"].map(severity).fillna(3)
        if "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°" in show.columns:
            show = show.sort_values(["__sev__", "é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°"], ascending=[True, True])
        show = show.drop(columns="__sev__", errors="ignore")

    if show.empty:
        st.info("æš‚æ— ç»Ÿè®¡ç»“æœã€‚è¯·æ£€æŸ¥ã€è´­å…¥/å‰©ä½™ã€è¡¨çš„è¡¨å¤´/æ•°æ®æ˜¯å¦å®Œæ•´ã€‚")
    st.dataframe(show, use_container_width=True)

    # å¯¼å‡º
    csv = show.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ å¯¼å‡ºç»Ÿè®¡ç»“æœï¼ˆCSVï¼‰", data=csv,
                       file_name=f"inventory_stats.csv", mime="text/csv")

    # ============ ä¸‹é’»ï¼šç‰©å“è¯¦æƒ… ============
    st.markdown("### ğŸ” ç‰©å“è¯¦æƒ…")
    detail_items = ["ï¼ˆä¸é€‰ï¼‰"] + list(show["é£Ÿæåç§° (Item Name)"].dropna().unique()) if "é£Ÿæåç§° (Item Name)" in show.columns else ["ï¼ˆä¸é€‰ï¼‰"]
    picked = st.selectbox("é€‰æ‹©ä¸€ä¸ªç‰©å“æŸ¥çœ‹è¯¦æƒ…", detail_items, index=0)

    if picked and picked != "ï¼ˆä¸é€‰ï¼‰":
        # ç»Ÿä¸€å£å¾„çš„â€œå½“å‰åº“å­˜â€ = æœ€åä¸€æ¬¡å‰©ä½™ + ä¹‹åä¹°å…¥
        item_df = normalize_columns_compute(df[df["é£Ÿæåç§° (Item Name)"] == picked].copy())
        item_df = item_df.reset_index(drop=False).rename(columns={"index": "__orig_idx__"})
        if "row_order" not in item_df.columns:
            item_df["row_order"] = item_df["__orig_idx__"]
        item_df = item_df.sort_values(["æ—¥æœŸ (Date)", "row_order"])

        rem = item_df[item_df.get("çŠ¶æ€ (Status)") == "å‰©ä½™"].copy()
        buy = item_df[item_df.get("çŠ¶æ€ (Status)") == "ä¹°å…¥"].copy()

        if len(rem):
            last_rem = rem.iloc[-1]
            last_date = last_rem["æ—¥æœŸ (Date)"]
            last_ord  = last_rem["row_order"]
            last_qty  = float(last_rem["æ•°é‡ (Qty)"]) if pd.notna(last_rem["æ•°é‡ (Qty)"]) else 0.0
            mask_after = (
                (item_df["æ—¥æœŸ (Date)"] > last_date) |
                ((item_df["æ—¥æœŸ (Date)"] == last_date) & (item_df["row_order"] > last_ord))
            )
            buys_after = item_df[mask_after & (item_df["çŠ¶æ€ (Status)"] == "ä¹°å…¥")]
            cur_stock = float(last_qty + buys_after["æ•°é‡ (Qty)"].sum())
        else:
            cur_stock = float(buy["æ•°é‡ (Qty)"].sum()) if len(buy) else float("nan")

        last_buy = buy.iloc[-1] if len(buy) else None
        last_buy_date = (last_buy["æ—¥æœŸ (Date)"].date().isoformat()
                         if last_buy is not None and pd.notna(last_buy["æ—¥æœŸ (Date)"]) else "â€”")
        last_buy_qty  = float(last_buy["æ•°é‡ (Qty)"]) if last_buy is not None else np.nan
        last_buy_price = float(last_buy["å•ä»· (Unit Price)"]) if (last_buy is not None and "å•ä»· (Unit Price)" in item_df.columns) else np.nan

        use14 = _recent_usage_14d_new(item_df)
        days_left = (cur_stock / (use14/14.0)) if (use14 and use14>0 and not np.isnan(cur_stock)) else np.nan
        stockout_date = (pd.Timestamp.today().normalize() + pd.Timedelta(days=float(days_left))).date().isoformat() \
                        if days_left == days_left else "â€”"

        if len(buy) >= 2:
            avg_interval = buy["æ—¥æœŸ (Date)"].diff().dt.days.dropna().mean()
        else:
            avg_interval = np.nan

        # KPI
        k1, k2, k3, k4, k5, k6 = st.columns(6)
        k1.metric("å½“å‰åº“å­˜", f"{0 if np.isnan(cur_stock) else cur_stock}")
        k2.metric("æœ€è¿‘14å¤©ç”¨é‡", f"{0 if not use14 else round(use14,2)}")
        k3.metric("é¢„è®¡è¿˜èƒ½ç”¨å¤©æ•°", "â€”" if np.isnan(days_left) else f"{days_left:.2f}")
        k4.metric("é¢„è®¡ç¼ºè´§æ—¥æœŸ", stockout_date)
        k5.metric("æœ€è¿‘é‡‡è´­æ—¥æœŸ", last_buy_date)
        k6.metric("å¹³å‡é‡‡è´­é—´éš”(å¤©)", "â€”" if np.isnan(avg_interval) else f"{avg_interval:.1f}")

        # åº“å­˜è½¨è¿¹ï¼ˆè¿‘60å¤©ï¼‰
        lookback = pd.Timestamp.today().normalize() - pd.Timedelta(days=60)
        rem60 = rem[rem["æ—¥æœŸ (Date)"] >= lookback].copy()
        if not rem60.empty:
            rem60["dt"] = pd.to_datetime(rem60["æ—¥æœŸ (Date)"])
            chart_stock = alt.Chart(rem60).mark_line(point=True).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q", title="å‰©ä½™æ•°é‡")
            ).properties(title=f"{picked} â€” å‰©ä½™æ•°é‡ï¼ˆè¿‘60å¤©ï¼‰")
            st.altair_chart(chart_stock, use_container_width=True)

        # äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰
        ev = item_df[item_df["æ—¥æœŸ (Date)"] >= lookback][["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)"]].copy()
        if not ev.empty:
            ev["dt"] = pd.to_datetime(ev["æ—¥æœŸ (Date)"])

            # é¢œè‰²æ˜ å°„ï¼šæŒ‰â€œä¹°å…¥/å‰©ä½™â€ä¸¤ç±»æŒ‡å®šå›ºå®šé¢œè‰²
            status_color = alt.Color(
                "çŠ¶æ€ (Status):N",
                scale=alt.Scale(
                    domain=["ä¹°å…¥", "å‰©ä½™"],               # ç±»åˆ«é¡ºåºï¼ˆç¡®ä¿é¢œè‰²ä¸ä¼šä¹±ï¼‰
                    range=["#1f77b4", "#E4572E"]          # å¯¹åº”é¢œè‰²ï¼ˆå¯æ”¹æˆä½ å–œæ¬¢çš„ï¼‰
                ),
                legend=alt.Legend(title="çŠ¶æ€")
            )

            chart_ev = alt.Chart(ev).mark_point(filled=True, size=80).encode(
                x=alt.X("dt:T", title="æ—¥æœŸ"),
                y=alt.Y("æ•°é‡ (Qty):Q"),
                color=status_color,                      # â† æ–°å¢ï¼šé¢œè‰²é€šé“
                shape="çŠ¶æ€ (Status):N",                 # ä¿ç•™å½¢çŠ¶åŒºåˆ†ï¼ˆå¯åˆ ï¼‰
                tooltip=["çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä»· (Unit Price)","æ—¥æœŸ (Date)"]
            ).properties(title=f"{picked} â€” äº‹ä»¶æ—¶é—´çº¿ï¼ˆè¿‘60å¤©ï¼‰")

            st.altair_chart(chart_ev, use_container_width=True)


        # æœ€è¿‘è®°å½•
        st.markdown("â€ƒ")
        st.markdown("#### æœ€è¿‘è®°å½•ï¼ˆåŸå§‹ï¼‰")
        cols = ["æ—¥æœŸ (Date)","çŠ¶æ€ (Status)","æ•°é‡ (Qty)","å•ä½ (Unit)","å•ä»· (Unit Price)","æ€»ä»· (Total Cost)","åˆ†ç±» (Category)","å¤‡æ³¨ (Notes)"]
        cols = [c for c in cols if c in item_df.columns]
        st.dataframe(item_df[cols].sort_values("æ—¥æœŸ (Date)").iloc[::-1].head(10), use_container_width=True)
